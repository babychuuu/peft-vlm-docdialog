{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcTFVksHF6m3",
        "outputId": "13238cc2-043f-48d9-f71f-9aca7829d059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezcKZuTpQWnm",
        "outputId": "b0358995-35fe-427e-8d4a-f95d0c5d8b60"
      },
      "outputs": [],
      "source": [
        "# 简单的Reranker评估脚本（不做清理）\n",
        "import re, json\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"安全的sigmoid函数\"\"\"\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "\n",
        "def load_reranker(kind=\"mini\"):\n",
        "    \"\"\"加载reranker模型\"\"\"\n",
        "    if kind == \"none\":\n",
        "        return None, None\n",
        "    if kind == \"mini\":\n",
        "        from sentence_transformers import CrossEncoder\n",
        "        model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "        def predict_fn(pairs):\n",
        "            raw_scores = model.predict(pairs)\n",
        "            # 应用sigmoid变换将logits转为概率\n",
        "            sigmoid_scores = sigmoid(np.array(raw_scores))\n",
        "            return sigmoid_scores.tolist()\n",
        "        return predict_fn, \"ms-marco-MiniLM\"\n",
        "    elif kind == \"bge\":\n",
        "        from FlagEmbedding import FlagReranker\n",
        "        import torch\n",
        "        rr = FlagReranker(\"BAAI/bge-reranker-large\", use_fp16=True)\n",
        "        def predict_fn(pairs):\n",
        "            scores = rr.compute_score(pairs)\n",
        "            if isinstance(scores, torch.Tensor):\n",
        "                scores = scores.sigmoid().tolist()\n",
        "            else:\n",
        "                scores = sigmoid(np.array(scores)).tolist()\n",
        "            return scores\n",
        "        return predict_fn, \"bge-reranker-large\"\n",
        "\n",
        "def extract_question_from_prompt(prompt: str) -> str:\n",
        "    \"\"\"从prompt中提取问题\"\"\"\n",
        "    if not isinstance(prompt, str):\n",
        "        return \"\"\n",
        "    m = re.search(r\"<\\|vision_end\\|>(.*)<\\|im_end\\|>\", prompt, re.DOTALL)\n",
        "    if m:\n",
        "        q = m.group(1)\n",
        "    else:\n",
        "        m2 = re.findall(r\"<\\|im_start\\|>user(.*)<\\|im_end\\|>\", prompt, re.DOTALL)\n",
        "        q = m2[-1] if m2 else \"\"\n",
        "    q = q.replace(\"\\r\",\" \").replace(\"\\n\",\" \")\n",
        "    while \"  \" in q:\n",
        "        q = q.replace(\"  \", \" \")\n",
        "    return q.strip()\n",
        "\n",
        "def pick_pred(x: dict):\n",
        "    return x.get(\"pred\") or x.get(\"prediction\") or x.get(\"output\") or x.get(\"response\") or x.get(\"answer\") or x.get(\"predict\")\n",
        "\n",
        "def pick_gold(x: dict):\n",
        "    return x.get(\"gold\") or x.get(\"reference\") or x.get(\"target\") or x.get(\"label\") or x.get(\"answer\")\n",
        "\n",
        "def pick_question(x: dict):\n",
        "    return x.get(\"question\") or x.get(\"query\") or extract_question_from_prompt(x.get(\"prompt\", \"\"))\n",
        "\n",
        "def normalize_text(s: str) -> str:\n",
        "    if s is None: return \"\"\n",
        "    s = s.strip().lower().replace(\"\\u00A0\",\" \").replace(\"\\t\",\" \")\n",
        "    while \"  \" in s: s = s.replace(\"  \",\" \")\n",
        "    out=[]; i=0\n",
        "    while i<len(s):\n",
        "        ch=s[i]\n",
        "        if ch==',' and i>0 and i+1<len(s) and s[i-1].isdigit() and s[i+1].isdigit():\n",
        "            i+=1; continue\n",
        "        out.append(ch); i+=1\n",
        "    return \"\".join(out)\n",
        "\n",
        "def simple_tokenize(s: str):\n",
        "    s = normalize_text(s)\n",
        "    return s.split() if s else []\n",
        "\n",
        "def edit_distance(a: str, b: str) -> int:\n",
        "    na, nb = len(a), len(b)\n",
        "    if na==0: return nb\n",
        "    if nb==0: return na\n",
        "    prev = list(range(nb+1)); curr=[0]*(nb+1)\n",
        "    for i in range(1,na+1):\n",
        "        curr[0]=i; ca=a[i-1]\n",
        "        for j in range(1,nb+1):\n",
        "            cb=b[j-1]; cost=0 if ca==cb else 1\n",
        "            curr[j]=min(prev[j]+1, curr[j-1]+1, prev[j-1]+cost)\n",
        "        prev, curr = curr, prev\n",
        "    return prev[nb]\n",
        "\n",
        "def anls_single(pred: str, gold: str) -> float:\n",
        "    pred, gold = normalize_text(pred), normalize_text(gold)\n",
        "    if pred==\"\" and gold==\"\": return 1.0\n",
        "    if pred==\"\" or gold==\"\":  return 0.0\n",
        "    d = edit_distance(pred, gold)\n",
        "    denom = max(len(pred), len(gold))\n",
        "    if denom==0: return 0.0\n",
        "    norm = d/denom\n",
        "    return (1.0-norm) if norm<0.5 else 0.0\n",
        "\n",
        "def exact_match(pred: str, gold: str) -> int:\n",
        "    return int(normalize_text(pred)==normalize_text(gold))\n",
        "\n",
        "def f1_token_level(pred: str, gold: str) -> float:\n",
        "    p = simple_tokenize(pred); g = simple_tokenize(gold)\n",
        "    if not p and not g: return 1.0\n",
        "    if not p or not g:  return 0.0\n",
        "    from collections import Counter\n",
        "    pc, gc = Counter(p), Counter(g)\n",
        "    overlap = sum((pc & gc).values())\n",
        "    if overlap==0: return 0.0\n",
        "    precision, recall = overlap/len(p), overlap/len(g)\n",
        "    return 2*precision*recall/(precision+recall)\n",
        "\n",
        "def extract_number(text: str) -> float:\n",
        "    \"\"\"从文本中提取数字\"\"\"\n",
        "    if not text:\n",
        "        return None\n",
        "\n",
        "    # 处理 thousand, million 等\n",
        "    text_lower = text.lower()\n",
        "    multipliers = {\n",
        "        'thousand': 1000, 'k': 1000,\n",
        "        'million': 1000000, 'm': 1000000,\n",
        "        'billion': 1000000000, 'b': 1000000000\n",
        "    }\n",
        "\n",
        "    for word, mult in multipliers.items():\n",
        "        if word in text_lower:\n",
        "            numbers = re.findall(r'\\d+(?:\\.\\d+)?', text)\n",
        "            if numbers:\n",
        "                try:\n",
        "                    return float(numbers[0]) * mult\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "    # 提取普通数字\n",
        "    cleaned = re.sub(r'[,%$]', '', text.strip())\n",
        "    numbers = re.findall(r'\\d+(?:\\.\\d+)?', cleaned)\n",
        "    if numbers:\n",
        "        try:\n",
        "            return float(numbers[0])\n",
        "        except:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def robust_number_comparison(pred: str, gold: str, tolerance=0.1) -> dict:\n",
        "    \"\"\"比较数字预测，允许一定容忍度\"\"\"\n",
        "    pred_num = extract_number(pred)\n",
        "    gold_num = extract_number(gold)\n",
        "\n",
        "    result = {\n",
        "        'pred_num': pred_num,\n",
        "        'gold_num': gold_num,\n",
        "        'exact_match': False,\n",
        "        'close_match': False,\n",
        "        'relative_error': None\n",
        "    }\n",
        "\n",
        "    if pred_num is not None and gold_num is not None:\n",
        "        if abs(pred_num - gold_num) < 0.001:\n",
        "            result['exact_match'] = True\n",
        "            result['close_match'] = True\n",
        "        elif gold_num > 0:\n",
        "            rel_error = abs(pred_num - gold_num) / gold_num\n",
        "            result['relative_error'] = rel_error\n",
        "            if rel_error <= tolerance:\n",
        "                result['close_match'] = True\n",
        "\n",
        "    return result\n",
        "\n",
        "def evaluate_with_reranker(input_path: str, reranker_kind=\"mini\"):\n",
        "    \"\"\"原始预测 + reranker评估（不做清理）\"\"\"\n",
        "    print(\"=== Evaluating with Reranker (No Cleaning) ===\")\n",
        "\n",
        "    # 加载reranker\n",
        "    predict_fn, rer_model = load_reranker(reranker_kind) if reranker_kind != \"none\" else (None, None)\n",
        "\n",
        "    # 读取数据\n",
        "    rows = []\n",
        "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            rows.append(json.loads(line))\n",
        "\n",
        "    print(f\"Total samples: {len(rows)}\")\n",
        "\n",
        "    # 计算所有指标\n",
        "    anls_list, em_list, f1_list = [], [], []\n",
        "    numeric_exact_list, numeric_close_list = [], []\n",
        "    rer_list = []\n",
        "    pairs = []\n",
        "\n",
        "    for x in rows:\n",
        "        pred = pick_pred(x)\n",
        "        gold = pick_gold(x)\n",
        "        question = pick_question(x)\n",
        "\n",
        "        # 传统指标\n",
        "        anls = anls_single(pred, gold)\n",
        "        em = exact_match(pred, gold)\n",
        "        f1 = f1_token_level(pred, gold)\n",
        "\n",
        "        x['anls'] = anls\n",
        "        x['em'] = em\n",
        "        x['f1'] = f1\n",
        "\n",
        "        anls_list.append(anls)\n",
        "        em_list.append(em)\n",
        "        f1_list.append(f1)\n",
        "\n",
        "        # 数字容忍指标\n",
        "        num_comp = robust_number_comparison(pred, gold, tolerance=0.15)  # 15%容忍度\n",
        "        if num_comp['pred_num'] is not None and num_comp['gold_num'] is not None:\n",
        "            numeric_exact_list.append(1 if num_comp['exact_match'] else 0)\n",
        "            numeric_close_list.append(1 if num_comp['close_match'] else 0)\n",
        "\n",
        "        # 为reranker准备数据\n",
        "        if predict_fn:\n",
        "            pairs.append((normalize_text(question), normalize_text(pred)))\n",
        "\n",
        "    # 计算reranker分数\n",
        "    if predict_fn and pairs:\n",
        "        print(f\"Computing reranker scores for {len(pairs)} pairs...\")\n",
        "        scores = predict_fn(pairs)\n",
        "        for r, s in zip(rows, scores):\n",
        "            if isinstance(s, (list, tuple)):\n",
        "                s = s[0]\n",
        "            r[\"reranker_score\"] = float(s)\n",
        "            rer_list.append(float(s))\n",
        "\n",
        "    # 汇总结果\n",
        "    metrics = {\n",
        "        'samples': len(rows),\n",
        "\n",
        "        # 传统指标\n",
        "        'anls_mean': np.mean(anls_list),\n",
        "        'anls_nonzero_coverage': sum(1 for v in anls_list if v > 0) / len(anls_list),\n",
        "        'em_mean': np.mean(em_list),\n",
        "        'f1_mean': np.mean(f1_list),\n",
        "\n",
        "        # 数字容忍指标\n",
        "        'numeric_samples': len(numeric_exact_list),\n",
        "        'numeric_exact_accuracy': np.mean(numeric_exact_list) if numeric_exact_list else 0,\n",
        "        'numeric_close_accuracy_15pct': np.mean(numeric_close_list) if numeric_close_list else 0,\n",
        "\n",
        "        # reranker指标\n",
        "        'reranker': reranker_kind,\n",
        "        'reranker_model': rer_model,\n",
        "    }\n",
        "\n",
        "    if rer_list:\n",
        "        r_sorted = sorted(rer_list)\n",
        "        metrics.update({\n",
        "            'reranker_mean': np.mean(rer_list),\n",
        "            'reranker_min': min(rer_list),\n",
        "            'reranker_max': max(rer_list),\n",
        "            'reranker_p50': r_sorted[len(r_sorted)//2],\n",
        "            'reranker_p90': r_sorted[int(0.9*(len(r_sorted)-1))],\n",
        "        })\n",
        "\n",
        "    print(\"\\n=== Final Results ===\")\n",
        "    print(json.dumps(metrics, indent=2))\n",
        "\n",
        "    # 保存带reranker分数的数据\n",
        "    output_path = input_path.replace(\".jsonl\", \".with_reranker.jsonl\")\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for row in rows:\n",
        "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    metrics_path = input_path.replace(\".jsonl\", \".final_metrics.json\")\n",
        "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"\\nSaved results to: {output_path}\")\n",
        "    print(f\"Saved metrics to: {metrics_path}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# 运行评估\n",
        "input_file = \"/content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infolastest/generated_predictions.jsonl\"\n",
        "\n",
        "# 可以选择不同的reranker: \"mini\", \"bge\", 或 \"none\"\n",
        "results = evaluate_with_reranker(input_file, reranker_kind=\"mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEgSxjoeSCin",
        "outputId": "7c365eb0-c8c3-4e1a-fa95-ead9236acd85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Evaluating with Reranker and Option Expansion ===\n",
            "Total samples: 535\n",
            "\n",
            "=== Expanding Options ===\n",
            "Expanded 0 option predictions\n",
            "Computing reranker scores for 535 pairs...\n",
            "\n",
            "=== Final Results ===\n",
            "{\n",
            "  \"samples\": 535,\n",
            "  \"option_expansion_enabled\": true,\n",
            "  \"expanded_predictions\": 0,\n",
            "  \"anls_mean\": 0.0990085488423102,\n",
            "  \"anls_nonzero_coverage\": 0.11962616822429907,\n",
            "  \"em_mean\": 0.05420560747663551,\n",
            "  \"f1_mean\": 0.1781307748654733,\n",
            "  \"original_anls_mean\": 0.1307216229894276,\n",
            "  \"original_em_mean\": 0.07663551401869159,\n",
            "  \"original_f1_mean\": 0.20578810146419727,\n",
            "  \"anls_improvement\": -0.03171307414711741,\n",
            "  \"em_improvement\": -0.02242990654205608,\n",
            "  \"f1_improvement\": -0.02765732659872397,\n",
            "  \"numeric_samples\": 295,\n",
            "  \"numeric_exact_accuracy\": 0.19661016949152543,\n",
            "  \"numeric_close_accuracy_15pct\": 0.27796610169491526,\n",
            "  \"reranker\": \"mini\",\n",
            "  \"reranker_model\": \"ms-marco-MiniLM\",\n",
            "  \"reranker_mean\": 0.13573839569559493,\n",
            "  \"reranker_min\": 1.0896051207964774e-05,\n",
            "  \"reranker_max\": 0.9999300241470337,\n",
            "  \"reranker_p50\": 0.0009621731587685645,\n",
            "  \"reranker_p90\": 0.6296535134315491,\n",
            "  \"original_reranker_mean\": 0.10125948500048355,\n",
            "  \"reranker_improvement\": 0.03447891069511137\n",
            "}\n",
            "\n",
            "Saved results to: /content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infolastest/generated_predictions.final_with_options.jsonl\n",
            "Saved metrics to: /content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infolastest/generated_predictions.final_metrics_with_options.json\n"
          ]
        }
      ],
      "source": [
        "# 带选项展开的Reranker评估脚本\n",
        "import re, json\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"安全的sigmoid函数\"\"\"\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "\n",
        "def load_reranker(kind=\"mini\"):\n",
        "    \"\"\"加载reranker模型\"\"\"\n",
        "    if kind == \"none\":\n",
        "        return None, None\n",
        "    if kind == \"mini\":\n",
        "        from sentence_transformers import CrossEncoder\n",
        "        model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "        def predict_fn(pairs):\n",
        "            raw_scores = model.predict(pairs)\n",
        "            # 应用sigmoid变换将logits转为概率\n",
        "            sigmoid_scores = sigmoid(np.array(raw_scores))\n",
        "            return sigmoid_scores.tolist()\n",
        "        return predict_fn, \"ms-marco-MiniLM\"\n",
        "    elif kind == \"bge\":\n",
        "        from FlagEmbedding import FlagReranker\n",
        "        import torch\n",
        "        rr = FlagReranker(\"BAAI/bge-reranker-large\", use_fp16=True)\n",
        "        def predict_fn(pairs):\n",
        "            scores = rr.compute_score(pairs)\n",
        "            if isinstance(scores, torch.Tensor):\n",
        "                scores = scores.sigmoid().tolist()\n",
        "            else:\n",
        "                scores = sigmoid(np.array(scores)).tolist()\n",
        "            return scores\n",
        "        return predict_fn, \"bge-reranker-large\"\n",
        "\n",
        "def extract_options_from_prompt(prompt: str) -> dict:\n",
        "    \"\"\"从prompt中提取选项映射\"\"\"\n",
        "    if not isinstance(prompt, str):\n",
        "        return {}\n",
        "\n",
        "    options = {}\n",
        "\n",
        "    # 模式1: A) xxx B) yyy C) zzz\n",
        "    pattern1 = r'([A-Z])\\)\\s*([^\\n\\r]+?)(?=\\s*[A-Z]\\)|$)'\n",
        "    matches1 = re.findall(pattern1, prompt, re.MULTILINE)\n",
        "    for letter, text in matches1:\n",
        "        options[letter.lower()] = text.strip()\n",
        "        # 也添加数字映射 A=1, B=2, etc.\n",
        "        options[str(ord(letter) - ord('A') + 1)] = text.strip()\n",
        "\n",
        "    # 模式2: 1) xxx 2) yyy 3) zzz\n",
        "    pattern2 = r'(\\d+)\\)\\s*([^\\n\\r]+?)(?=\\s*\\d+\\)|$)'\n",
        "    matches2 = re.findall(pattern2, prompt, re.MULTILINE)\n",
        "    for num, text in matches2:\n",
        "        options[num] = text.strip()\n",
        "\n",
        "    # 模式3: 1. xxx 2. yyy 3. zzz\n",
        "    pattern3 = r'(\\d+)\\.\\s*([^\\n\\r]+?)(?=\\s*\\d+\\.|$)'\n",
        "    matches3 = re.findall(pattern3, prompt, re.MULTILINE)\n",
        "    for num, text in matches3:\n",
        "        options[num] = text.strip()\n",
        "\n",
        "    # 模式4: A. xxx B. yyy C. zzz\n",
        "    pattern4 = r'([A-Z])\\.\\s*([^\\n\\r]+?)(?=\\s*[A-Z]\\.|$)'\n",
        "    matches4 = re.findall(pattern4, prompt, re.MULTILINE)\n",
        "    for letter, text in matches4:\n",
        "        options[letter.lower()] = text.strip()\n",
        "        options[str(ord(letter) - ord('A') + 1)] = text.strip()\n",
        "\n",
        "    # 清理选项文本\n",
        "    cleaned_options = {}\n",
        "    for key, value in options.items():\n",
        "        # 移除前后空白和标点\n",
        "        clean_value = re.sub(r'^[^\\w]*|[^\\w]*$', '', value)\n",
        "        if clean_value and len(clean_value) > 1:  # 至少2个字符\n",
        "            cleaned_options[key] = clean_value\n",
        "\n",
        "    return cleaned_options\n",
        "\n",
        "def is_option_answer(pred: str) -> bool:\n",
        "    \"\"\"判断是否是选项答案（单个字母或数字）\"\"\"\n",
        "    pred = pred.strip().lower()\n",
        "    return bool(re.match(r'^[a-z]$|^\\d+$', pred)) and len(pred) <= 2\n",
        "\n",
        "def expand_prediction(pred: str, prompt: str) -> str:\n",
        "    \"\"\"展开预测：如果是选项编号，转换为对应文本\"\"\"\n",
        "    if not is_option_answer(pred):\n",
        "        return pred\n",
        "\n",
        "    options = extract_options_from_prompt(prompt)\n",
        "    pred_clean = pred.strip().lower()\n",
        "\n",
        "    if pred_clean in options:\n",
        "        expanded = options[pred_clean]\n",
        "        print(f\"Expanded option: '{pred}' -> '{expanded}'\")\n",
        "        return expanded\n",
        "\n",
        "    return pred  # 找不到对应选项，返回原值\n",
        "\n",
        "def extract_question_from_prompt(prompt: str) -> str:\n",
        "    \"\"\"从prompt中提取问题\"\"\"\n",
        "    if not isinstance(prompt, str):\n",
        "        return \"\"\n",
        "    m = re.search(r\"<\\|vision_end\\|>(.*)<\\|im_end\\|>\", prompt, re.DOTALL)\n",
        "    if m:\n",
        "        q = m.group(1)\n",
        "    else:\n",
        "        m2 = re.findall(r\"<\\|im_start\\|>user(.*)<\\|im_end\\|>\", prompt, re.DOTALL)\n",
        "        q = m2[-1] if m2 else \"\"\n",
        "    q = q.replace(\"\\r\",\" \").replace(\"\\n\",\" \")\n",
        "    while \"  \" in q:\n",
        "        q = q.replace(\"  \", \" \")\n",
        "    return q.strip()\n",
        "\n",
        "def pick_pred(x: dict):\n",
        "    return x.get(\"pred\") or x.get(\"prediction\") or x.get(\"output\") or x.get(\"response\") or x.get(\"answer\") or x.get(\"predict\")\n",
        "\n",
        "def pick_gold(x: dict):\n",
        "    return x.get(\"gold\") or x.get(\"reference\") or x.get(\"target\") or x.get(\"label\") or x.get(\"answer\")\n",
        "\n",
        "def pick_question(x: dict):\n",
        "    return x.get(\"question\") or x.get(\"query\") or extract_question_from_prompt(x.get(\"prompt\", \"\"))\n",
        "\n",
        "def normalize_text(s: str) -> str:\n",
        "    if s is None: return \"\"\n",
        "    s = s.strip().lower().replace(\"\\u00A0\",\" \").replace(\"\\t\",\" \")\n",
        "    while \"  \" in s: s = s.replace(\"  \",\" \")\n",
        "    out=[]; i=0\n",
        "    while i<len(s):\n",
        "        ch=s[i]\n",
        "        if ch==',' and i>0 and i+1<len(s) and s[i-1].isdigit() and s[i+1].isdigit():\n",
        "            i+=1; continue\n",
        "        out.append(ch); i+=1\n",
        "    return \"\".join(out)\n",
        "\n",
        "def simple_tokenize(s: str):\n",
        "    s = normalize_text(s)\n",
        "    return s.split() if s else []\n",
        "\n",
        "def edit_distance(a: str, b: str) -> int:\n",
        "    na, nb = len(a), len(b)\n",
        "    if na==0: return nb\n",
        "    if nb==0: return na\n",
        "    prev = list(range(nb+1)); curr=[0]*(nb+1)\n",
        "    for i in range(1,na+1):\n",
        "        curr[0]=i; ca=a[i-1]\n",
        "        for j in range(1,nb+1):\n",
        "            cb=b[j-1]; cost=0 if ca==cb else 1\n",
        "            curr[j]=min(prev[j]+1, curr[j-1]+1, prev[j-1]+cost)\n",
        "        prev, curr = curr, prev\n",
        "    return prev[nb]\n",
        "\n",
        "def anls_single(pred: str, gold: str) -> float:\n",
        "    pred, gold = normalize_text(pred), normalize_text(gold)\n",
        "    if pred==\"\" and gold==\"\": return 1.0\n",
        "    if pred==\"\" or gold==\"\":  return 0.0\n",
        "    d = edit_distance(pred, gold)\n",
        "    denom = max(len(pred), len(gold))\n",
        "    if denom==0: return 0.0\n",
        "    norm = d/denom\n",
        "    return (1.0-norm) if norm<0.5 else 0.0\n",
        "\n",
        "def exact_match(pred: str, gold: str) -> int:\n",
        "    return int(normalize_text(pred)==normalize_text(gold))\n",
        "\n",
        "def f1_token_level(pred: str, gold: str) -> float:\n",
        "    p = simple_tokenize(pred); g = simple_tokenize(gold)\n",
        "    if not p and not g: return 1.0\n",
        "    if not p or not g:  return 0.0\n",
        "    from collections import Counter\n",
        "    pc, gc = Counter(p), Counter(g)\n",
        "    overlap = sum((pc & gc).values())\n",
        "    if overlap==0: return 0.0\n",
        "    precision, recall = overlap/len(p), overlap/len(g)\n",
        "    return 2*precision*recall/(precision+recall)\n",
        "\n",
        "def extract_number(text: str) -> float:\n",
        "    \"\"\"从文本中提取数字\"\"\"\n",
        "    if not text:\n",
        "        return None\n",
        "\n",
        "    # 处理 thousand, million 等\n",
        "    text_lower = text.lower()\n",
        "    multipliers = {\n",
        "        'thousand': 1000, 'k': 1000,\n",
        "        'million': 1000000, 'm': 1000000,\n",
        "        'billion': 1000000000, 'b': 1000000000\n",
        "    }\n",
        "\n",
        "    for word, mult in multipliers.items():\n",
        "        if word in text_lower:\n",
        "            numbers = re.findall(r'\\d+(?:\\.\\d+)?', text)\n",
        "            if numbers:\n",
        "                try:\n",
        "                    return float(numbers[0]) * mult\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "    # 提取普通数字\n",
        "    cleaned = re.sub(r'[,%$]', '', text.strip())\n",
        "    numbers = re.findall(r'\\d+(?:\\.\\d+)?', cleaned)\n",
        "    if numbers:\n",
        "        try:\n",
        "            return float(numbers[0])\n",
        "        except:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def robust_number_comparison(pred: str, gold: str, tolerance=0.1) -> dict:\n",
        "    \"\"\"比较数字预测，允许一定容忍度\"\"\"\n",
        "    pred_num = extract_number(pred)\n",
        "    gold_num = extract_number(gold)\n",
        "\n",
        "    result = {\n",
        "        'pred_num': pred_num,\n",
        "        'gold_num': gold_num,\n",
        "        'exact_match': False,\n",
        "        'close_match': False,\n",
        "        'relative_error': None\n",
        "    }\n",
        "\n",
        "    if pred_num is not None and gold_num is not None:\n",
        "        if abs(pred_num - gold_num) < 0.001:\n",
        "            result['exact_match'] = True\n",
        "            result['close_match'] = True\n",
        "        elif gold_num > 0:\n",
        "            rel_error = abs(pred_num - gold_num) / gold_num\n",
        "            result['relative_error'] = rel_error\n",
        "            if rel_error <= tolerance:\n",
        "                result['close_match'] = True\n",
        "\n",
        "    return result\n",
        "\n",
        "def evaluate_with_options_and_reranker(input_path: str, reranker_kind=\"mini\", expand_options=True):\n",
        "    \"\"\"原始预测 + reranker评估 + 选项展开\"\"\"\n",
        "    print(\"=== Evaluating with Reranker and Option Expansion ===\")\n",
        "\n",
        "    # 加载reranker\n",
        "    predict_fn, rer_model = load_reranker(reranker_kind) if reranker_kind != \"none\" else (None, None)\n",
        "\n",
        "    # 读取数据\n",
        "    rows = []\n",
        "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            rows.append(json.loads(line))\n",
        "\n",
        "    print(f\"Total samples: {len(rows)}\")\n",
        "\n",
        "    # 选项展开\n",
        "    expanded_count = 0\n",
        "    if expand_options:\n",
        "        print(\"\\n=== Expanding Options ===\")\n",
        "        for x in rows:\n",
        "            original_pred = pick_pred(x)\n",
        "            prompt = x.get(\"prompt\", \"\")\n",
        "            expanded_pred = expand_prediction(original_pred, prompt)\n",
        "\n",
        "            if expanded_pred != original_pred:\n",
        "                expanded_count += 1\n",
        "                x['expanded_pred'] = expanded_pred\n",
        "            else:\n",
        "                x['expanded_pred'] = original_pred\n",
        "\n",
        "        print(f\"Expanded {expanded_count} option predictions\")\n",
        "\n",
        "    # 选择使用哪个预测\n",
        "    def get_final_pred(x: dict):\n",
        "        if expand_options:\n",
        "            return x.get('expanded_pred', pick_pred(x))\n",
        "        else:\n",
        "            return pick_pred(x)\n",
        "\n",
        "    # 计算所有指标\n",
        "    anls_list, em_list, f1_list = [], [], []\n",
        "    numeric_exact_list, numeric_close_list = [], []\n",
        "    rer_list = []\n",
        "    pairs = []\n",
        "\n",
        "    for x in rows:\n",
        "        pred = get_final_pred(x)\n",
        "        gold = pick_gold(x)\n",
        "        question = pick_question(x)\n",
        "\n",
        "        # 传统指标\n",
        "        anls = anls_single(pred, gold)\n",
        "        em = exact_match(pred, gold)\n",
        "        f1 = f1_token_level(pred, gold)\n",
        "\n",
        "        x['final_anls'] = anls\n",
        "        x['final_em'] = em\n",
        "        x['final_f1'] = f1\n",
        "\n",
        "        anls_list.append(anls)\n",
        "        em_list.append(em)\n",
        "        f1_list.append(f1)\n",
        "\n",
        "        # 数字容忍指标\n",
        "        num_comp = robust_number_comparison(pred, gold, tolerance=0.15)  # 15%容忍度\n",
        "        if num_comp['pred_num'] is not None and num_comp['gold_num'] is not None:\n",
        "            numeric_exact_list.append(1 if num_comp['exact_match'] else 0)\n",
        "            numeric_close_list.append(1 if num_comp['close_match'] else 0)\n",
        "\n",
        "        # 为reranker准备数据\n",
        "        if predict_fn:\n",
        "            pairs.append((normalize_text(question), normalize_text(pred)))\n",
        "\n",
        "    # 计算reranker分数\n",
        "    if predict_fn and pairs:\n",
        "        print(f\"Computing reranker scores for {len(pairs)} pairs...\")\n",
        "        scores = predict_fn(pairs)\n",
        "        for r, s in zip(rows, scores):\n",
        "            if isinstance(s, (list, tuple)):\n",
        "                s = s[0]\n",
        "            r[\"reranker_score\"] = float(s)\n",
        "            rer_list.append(float(s))\n",
        "\n",
        "    # 汇总结果\n",
        "    metrics = {\n",
        "        'samples': len(rows),\n",
        "        'option_expansion_enabled': expand_options,\n",
        "        'expanded_predictions': expanded_count if expand_options else 0,\n",
        "\n",
        "        # 传统指标\n",
        "        'anls_mean': np.mean(anls_list),\n",
        "        'anls_nonzero_coverage': sum(1 for v in anls_list if v > 0) / len(anls_list),\n",
        "        'em_mean': np.mean(em_list),\n",
        "        'f1_mean': np.mean(f1_list),\n",
        "\n",
        "        # 对比原始结果\n",
        "        'original_anls_mean': 0.1307216229894276,\n",
        "        'original_em_mean': 0.07663551401869159,\n",
        "        'original_f1_mean': 0.20578810146419727,\n",
        "        'anls_improvement': np.mean(anls_list) - 0.1307216229894276,\n",
        "        'em_improvement': np.mean(em_list) - 0.07663551401869159,\n",
        "        'f1_improvement': np.mean(f1_list) - 0.20578810146419727,\n",
        "\n",
        "        # 数字容忍指标\n",
        "        'numeric_samples': len(numeric_exact_list),\n",
        "        'numeric_exact_accuracy': np.mean(numeric_exact_list) if numeric_exact_list else 0,\n",
        "        'numeric_close_accuracy_15pct': np.mean(numeric_close_list) if numeric_close_list else 0,\n",
        "\n",
        "        # reranker指标\n",
        "        'reranker': reranker_kind,\n",
        "        'reranker_model': rer_model,\n",
        "    }\n",
        "\n",
        "    if rer_list:\n",
        "        r_sorted = sorted(rer_list)\n",
        "        metrics.update({\n",
        "            'reranker_mean': np.mean(rer_list),\n",
        "            'reranker_min': min(rer_list),\n",
        "            'reranker_max': max(rer_list),\n",
        "            'reranker_p50': r_sorted[len(r_sorted)//2],\n",
        "            'reranker_p90': r_sorted[int(0.9*(len(r_sorted)-1))],\n",
        "            'original_reranker_mean': 0.10125948500048355,\n",
        "            'reranker_improvement': np.mean(rer_list) - 0.10125948500048355,\n",
        "        })\n",
        "\n",
        "    print(\"\\n=== Final Results ===\")\n",
        "    print(json.dumps(metrics, indent=2))\n",
        "\n",
        "    # 保存结果\n",
        "    output_path = input_path.replace(\".jsonl\", \".final_with_options.jsonl\")\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for row in rows:\n",
        "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    metrics_path = input_path.replace(\".jsonl\", \".final_metrics_with_options.json\")\n",
        "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"\\nSaved results to: {output_path}\")\n",
        "    print(f\"Saved metrics to: {metrics_path}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# 运行评估（包含选项展开）\n",
        "input_file = \"/content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infolastest/generated_predictions.jsonl\"\n",
        "\n",
        "# 可以选择不同的reranker: \"mini\", \"bge\", 或 \"none\"\n",
        "# expand_options=True 会将 1/2/3 转换为对应的选项文本\n",
        "results = evaluate_with_options_and_reranker(input_file, reranker_kind=\"mini\", expand_options=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms7subxAmRMZ"
      },
      "source": [
        "vblora on vqa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e7038e8fd0c448378b5026fc61e94a95",
            "4eded3bbeddd45ae8159e8c8f64eba73",
            "926b0aa07a3b41e2bd5ad58fe42e00e7",
            "0b5dbf99ed0d440b9f147f59e31f68c5",
            "76994a1ec3254211919ace0017ae567a",
            "5936f7f3f0f64fd59e54b4a9aae28753",
            "a21b184b118d4fec87b54ca1f0c3c432",
            "61cb1e94144b475eb42d0bf65653188c",
            "068c7727c0ec40e5ab8871e8e3c26faf",
            "7f6ada349ee24bb0b8c8208364b183c8",
            "1dd07dbfe884433596959542cc7afc3a",
            "c842cb4c289b4e8db51a190bef08d1b5",
            "b24d789382f143e08dfd50a2d81c59dc",
            "cd027e14421249018037d6d4406b7fe0",
            "272d6e662ee144a9b4e4ac813911f000",
            "ec359cc2e0d749e1887e8f55a0eb0f67",
            "2d7889d15aef4996a9d79ee9101c5c00",
            "bd9e830ffc0d4135a0da9ee43631a5ba",
            "18cbee89399c4e3db6a92a264bbf161c",
            "58d24bf56a4541bdb90c56ad12b80399",
            "2118c51adb6f4f978534760011a1e35b",
            "cd9ffe2f57864c6abb50ec809ac0ded9",
            "a91fe0f14db74a0f8d6dd6ed6a96c7fa",
            "36192f189ebc4f68a9f594c009481477",
            "37b4c344892849569ac29eef13216bba",
            "cd9e12817c17405c8784264a67f0c045",
            "304d69dd47e446cca66abf74528c5f0a",
            "cdd3282c594841658fb7383e27a80957",
            "e96f6b0cbfdb491d95f57e7cdc080bfd",
            "e08847a1e9974824be13fe6cab5dbe81",
            "fbe36e500d574abfa8b738a48a1b0d9b",
            "39a94c52445f40348498a6c7e587566d",
            "08a75c4f551f4e4a9cf150c23070a9b0",
            "4d1c69f74dae402ca79e06b9fb082a1e",
            "9f2f9702348647c0a8d3bc7db1b2ca80",
            "46c13e0346424e678996341ca7491f7a",
            "5046908e401e48deb147026f37efaef5",
            "c111c1d6d3164b0b8c49a762f5b1f68f",
            "9f431445631749eca952fb8ce9a18dc5",
            "b95dbd5f636d4dbf87415b1c88350f26",
            "361d2d3c655640ac94b69ff617a28b63",
            "a13b37cfc4c743c8989932f83c0d204e",
            "8cc559e9b9b94b479b7d5a179818034d",
            "4420891b52d04fe5b2c23662e0e9a927",
            "3e4f92e2d6854b0096e8bb1104fa84c9",
            "43d4039d72e742ca8394654df2a4f88a",
            "f988e0f3d1fb4f0db7e2c24c87c8c4cf",
            "da0e9fea99a843cea1d152661af20754",
            "43d3ed54570940989c30b953d5dcbba8",
            "0731eac36abe4fefa56eb9d072e887a0",
            "2ab40afb7c9c4987a4f21efe494cd61e",
            "b824ea81c26a4d2f8024089cd139b472",
            "f0c34de623e9465ea1993e99d44d6f6a",
            "b8b697a08d7148c2a75285cf73b2c3f1",
            "91a129ff80ce44a28abe62acc4a24085",
            "20601b4d02d04ae498532424e80217f0",
            "e06ee01dff6e4968a9abb2a3f37b0393",
            "7647c8eaa4ec4c02be1951d49fef33ab",
            "401f886141bd4d4a8651dc4908bbe2cd",
            "7a8cc50b39e14ee395125f27511fe60b",
            "e720ed9ea3e64d64b3850e3247b6cf42",
            "8b204a6cac4841719f2493e91a50b9db",
            "c6fccedcf8e745a69a433201528b3d39",
            "73be6589f4504122865ad374d62c94f9",
            "d8c071bee4434ad49ade2ce4815678ba",
            "238cf2e5927c4bb281c034a2eba6e293"
          ]
        },
        "id": "bQNqRjWLxolw",
        "outputId": "dc687557-d064-4154-c9c0-c5bb3150aba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Comprehensive Evaluation: Cleaning + Reranker ===\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7038e8fd0c448378b5026fc61e94a95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c842cb4c289b4e8db51a190bef08d1b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a91fe0f14db74a0f8d6dd6ed6a96c7fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d1c69f74dae402ca79e06b9fb082a1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e4f92e2d6854b0096e8bb1104fa84c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/801 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20601b4d02d04ae498532424e80217f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from: /content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infovblastest/generated_predictions.jsonl\n",
            "Total samples: 535\n",
            "\n",
            "=== Step 1: Cleaning Predictions ===\n",
            "\n",
            "Sample 0:\n",
            "  Original: Pinterest Pinterest, Pinterest, Pinterest[2] Pinterest, Pinterest, Pinterest is a social media platf...\n",
            "  Cleaned:  pinterest\n",
            "  Gold:     pinterest\n",
            "\n",
            "\n",
            "Sample 1:\n",
            "  Original: Rest: Social media platform cheat sheet, Social media platform cheat sheet, Retail, Nonprofits, News...\n",
            "  Cleaned:  Social, media, platform\n",
            "  Gold:     restaurants, interior design, wedding venues\n",
            "\n",
            "\n",
            "Sample 2:\n",
            "  Original: Facebook, Instagram, Instagram, Instagram is good for B2B companies, Instagram, Instagram is good fo...\n",
            "  Cleaned:  facebook\n",
            "  Gold:     linkedin, facebook\n",
            "\n",
            "Cleaned 126 long predictions (>200 chars)\n",
            "\n",
            "=== Step 2: Computing Traditional Metrics ===\n",
            "\n",
            "=== Step 3: Computing Reranker Scores ===\n",
            "Computing reranker scores for 469 original pairs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "pre tokenize:   0%|          | 0/4 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "pre tokenize: 100%|██████████| 4/4 [00:00<00:00, 93.34it/s]\n",
            "Compute Scores: 100%|██████████| 4/4 [00:00<00:00, 22.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing reranker scores for 469 cleaned pairs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "pre tokenize: 100%|██████████| 4/4 [00:00<00:00, 113.81it/s]\n",
            "Compute Scores: 100%|██████████| 4/4 [00:00<00:00, 21.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Step 4: Results Summary ===\n",
            "Results:\n",
            "  Original ANLS: 0.0015\n",
            "  Cleaned ANLS:  0.0344\n",
            "  ANLS Improvement: 0.0329\n",
            "  Original EM: 0.0000\n",
            "  Cleaned EM:  0.0187\n",
            "  EM Improvement: 0.0187\n",
            "  Original F1: 0.0344\n",
            "  Cleaned F1:  0.0648\n",
            "  F1 Improvement: 0.0304\n",
            "  Original Reranker: 0.3394\n",
            "  Cleaned Reranker:  0.2676\n",
            "  Reranker Improvement: -0.0718\n",
            "  Improved cases: 38\n",
            "\n",
            "=== Top Improvement Cases ===\n",
            "Case 1:\n",
            "  Original: Pinterest Pinterest, Pinterest, Pinterest[2] Pinterest, Pinterest, Pinterest is ...\n",
            "  Cleaned:  pinterest\n",
            "  Gold:     pinterest\n",
            "\n",
            "  EM: 0 -> 1\n",
            "  F1: 0.059 -> 1.000\n",
            "\n",
            "Case 2:\n",
            "  Original: Facebook, Instagram, Instagram, Instagram is good for B2B companies, Instagram, ...\n",
            "  Cleaned:  facebook\n",
            "  Gold:     linkedin, facebook\n",
            "\n",
            "  EM: 0 -> 0\n",
            "  F1: 0.061 -> 0.667\n",
            "\n",
            "Case 3:\n",
            "  Original: LinkedIn, LinkedIn, LinkedIn, LinkedInthe platform, LinkedIn, LinkedIn, LinkedIn...\n",
            "  Cleaned:  linkedin\n",
            "  Gold:     linkedin\n",
            "\n",
            "  EM: 0 -> 1\n",
            "  F1: 0.077 -> 1.000\n",
            "\n",
            "\n",
            "Saved detailed results to: /content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infovblastest/generated_predictions_comprehensive_results.jsonl\n",
            "Saved metrics to: /content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infovblastest/generated_predictions_comprehensive_metrics.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"安全的sigmoid函数\"\"\"\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "\n",
        "def load_reranker(kind=\"mini\"):\n",
        "    \"\"\"加载reranker模型\"\"\"\n",
        "    if kind == \"none\":\n",
        "        return None, None\n",
        "    if kind == \"mini\":\n",
        "        from sentence_transformers import CrossEncoder\n",
        "        model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "        def predict_fn(pairs):\n",
        "            raw_scores = model.predict(pairs)\n",
        "            sigmoid_scores = sigmoid(np.array(raw_scores))\n",
        "            return sigmoid_scores.tolist()\n",
        "        return predict_fn, \"ms-marco-MiniLM\"\n",
        "    elif kind == \"bge\":\n",
        "        from FlagEmbedding import FlagReranker\n",
        "        import torch\n",
        "        rr = FlagReranker(\"BAAI/bge-reranker-large\", use_fp16=True)\n",
        "        def predict_fn(pairs):\n",
        "            scores = rr.compute_score(pairs)\n",
        "            if isinstance(scores, torch.Tensor):\n",
        "                scores = scores.sigmoid().tolist()\n",
        "            else:\n",
        "                scores = sigmoid(np.array(scores)).tolist()\n",
        "            return scores\n",
        "        return predict_fn, \"bge-reranker-large\"\n",
        "\n",
        "def extract_keywords_from_prediction(prediction: str, top_n=5) -> str:\n",
        "    \"\"\"从冗长的预测中提取关键词\"\"\"\n",
        "    if not prediction:\n",
        "        return \"\"\n",
        "\n",
        "    # 1. 清理文本\n",
        "    text = prediction.lower()\n",
        "\n",
        "    # 2. 移除重复的句子片段\n",
        "    sentences = re.split(r'[.!?]\\s*', text)\n",
        "    unique_sentences = []\n",
        "    seen = set()\n",
        "    for sent in sentences:\n",
        "        sent = sent.strip()\n",
        "        if sent and sent not in seen and len(sent) > 10:\n",
        "            seen.add(sent)\n",
        "            unique_sentences.append(sent)\n",
        "\n",
        "    # 3. 提取候选关键词\n",
        "    candidates = []\n",
        "\n",
        "    # 方法1: 提取开头的词汇（通常是答案）\n",
        "    first_words = re.findall(r'\\b[a-zA-Z]+\\b', prediction[:200])\n",
        "    candidates.extend(first_words[:10])\n",
        "\n",
        "    # 方法2: 提取品牌/平台名称\n",
        "    platform_keywords = [\n",
        "        'pinterest', 'facebook', 'instagram', 'linkedin', 'twitter',\n",
        "        'youtube', 'tiktok', 'snapchat', 'whatsapp', 'telegram',\n",
        "        'restaurants', 'interior design', 'wedding venues', 'fashion',\n",
        "        'food', 'travel', 'photography', 'art', 'design', 'business',\n",
        "        'home', 'decor', 'style', 'beauty', 'fitness', 'health'\n",
        "    ]\n",
        "\n",
        "    for keyword in platform_keywords:\n",
        "        if keyword in text:\n",
        "            candidates.append(keyword)\n",
        "\n",
        "    # 方法3: 提取逗号分隔的词汇\n",
        "    comma_separated = re.findall(r'\\b[a-zA-Z\\s]+(?=,|\\.|$)', text[:300])\n",
        "    for item in comma_separated:\n",
        "        item = item.strip()\n",
        "        if item and len(item.split()) <= 3:  # 最多3个词\n",
        "            candidates.append(item)\n",
        "\n",
        "    # 4. 统计词频并选择最佳答案\n",
        "    word_counts = Counter()\n",
        "    for candidate in candidates:\n",
        "        if candidate and len(candidate) > 1:\n",
        "            clean_candidate = re.sub(r'[^\\w\\s,]', '', candidate).strip()\n",
        "            if clean_candidate:\n",
        "                word_counts[clean_candidate] += 1\n",
        "\n",
        "    # 5. 选择最频繁的关键词\n",
        "    if word_counts:\n",
        "        # 优先选择平台关键词\n",
        "        for keyword in platform_keywords:\n",
        "            if keyword in word_counts:\n",
        "                return keyword\n",
        "\n",
        "        # 否则选择最频繁的词\n",
        "        most_common = word_counts.most_common(top_n)\n",
        "        best_candidates = [word for word, count in most_common if count >= 1]\n",
        "\n",
        "        if best_candidates:\n",
        "            return ', '.join(best_candidates[:3])  # 最多3个关键词\n",
        "\n",
        "    # 6. 如果都失败，返回前几个有意义的词\n",
        "    words = re.findall(r'\\b[a-zA-Z]+\\b', prediction[:100])\n",
        "    meaningful_words = [w for w in words if len(w) > 2 and w.lower() not in\n",
        "                       ['the', 'and', 'for', 'are', 'this', 'that', 'with', 'have', 'will']]\n",
        "\n",
        "    if meaningful_words:\n",
        "        return ', '.join(meaningful_words[:3])\n",
        "\n",
        "    return prediction[:50].strip()  # 最后的备选方案\n",
        "\n",
        "def extract_question_from_prompt(prompt: str) -> str:\n",
        "    \"\"\"从prompt中提取问题\"\"\"\n",
        "    if not isinstance(prompt, str):\n",
        "        return \"\"\n",
        "    m = re.search(r\"<\\|vision_end\\|>(.*)<\\|im_end\\|>\", prompt, re.DOTALL)\n",
        "    if m:\n",
        "        q = m.group(1)\n",
        "    else:\n",
        "        m2 = re.findall(r\"<\\|im_start\\|>user(.*)<\\|im_end\\|>\", prompt, re.DOTALL)\n",
        "        q = m2[-1] if m2 else \"\"\n",
        "    q = q.replace(\"\\r\",\" \").replace(\"\\n\",\" \")\n",
        "    while \"  \" in q:\n",
        "        q = q.replace(\"  \", \" \")\n",
        "    return q.strip()\n",
        "\n",
        "def normalize_text(s: str) -> str:\n",
        "    if s is None: return \"\"\n",
        "    s = str(s).strip().lower().replace(\"\\u00A0\",\" \").replace(\"\\t\",\" \")\n",
        "    while \"  \" in s: s = s.replace(\"  \",\" \")\n",
        "    return s\n",
        "\n",
        "def simple_tokenize(s: str):\n",
        "    s = normalize_text(s)\n",
        "    return s.split() if s else []\n",
        "\n",
        "def edit_distance(a: str, b: str) -> int:\n",
        "    na, nb = len(a), len(b)\n",
        "    if na==0: return nb\n",
        "    if nb==0: return na\n",
        "    prev = list(range(nb+1)); curr=[0]*(nb+1)\n",
        "    for i in range(1,na+1):\n",
        "        curr[0]=i; ca=a[i-1]\n",
        "        for j in range(1,nb+1):\n",
        "            cb=b[j-1]; cost=0 if ca==cb else 1\n",
        "            curr[j]=min(prev[j]+1, curr[j-1]+1, prev[j-1]+cost)\n",
        "        prev, curr = curr, prev\n",
        "    return prev[nb]\n",
        "\n",
        "def anls_single(pred: str, gold: str) -> float:\n",
        "    pred, gold = normalize_text(pred), normalize_text(gold)\n",
        "    if pred==\"\" and gold==\"\": return 1.0\n",
        "    if pred==\"\" or gold==\"\":  return 0.0\n",
        "    d = edit_distance(pred, gold)\n",
        "    denom = max(len(pred), len(gold))\n",
        "    if denom==0: return 0.0\n",
        "    norm = d/denom\n",
        "    return (1.0-norm) if norm<0.5 else 0.0\n",
        "\n",
        "def exact_match(pred: str, gold: str) -> int:\n",
        "    return int(normalize_text(pred) == normalize_text(gold))\n",
        "\n",
        "def f1_token_level(pred: str, gold: str) -> float:\n",
        "    p = simple_tokenize(pred); g = simple_tokenize(gold)\n",
        "    if not p and not g: return 1.0\n",
        "    if not p or not g:  return 0.0\n",
        "\n",
        "    pc, gc = Counter(p), Counter(g)\n",
        "    overlap = sum((pc & gc).values())\n",
        "    if overlap==0: return 0.0\n",
        "    precision, recall = overlap/len(p), overlap/len(g)\n",
        "    return 2*precision*recall/(precision+recall)\n",
        "\n",
        "def comprehensive_evaluate_with_cleaning_and_reranker(input_path: str, reranker_kind=\"mini\", cleaning_threshold=200):\n",
        "    \"\"\"整合清理和reranker的综合评估\"\"\"\n",
        "    print(\"=== Comprehensive Evaluation: Cleaning + Reranker ===\")\n",
        "\n",
        "    # 加载reranker\n",
        "    predict_fn, rer_model = load_reranker(reranker_kind) if reranker_kind != \"none\" else (None, None)\n",
        "\n",
        "    # 读取数据\n",
        "    print(f\"Loading data from: {input_path}\")\n",
        "    rows = []\n",
        "    with open(input_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                rows.append(json.loads(line))\n",
        "\n",
        "    print(f\"Total samples: {len(rows)}\")\n",
        "\n",
        "    # === 第一步：清理预测 ===\n",
        "    print(f\"\\n=== Step 1: Cleaning Predictions ===\")\n",
        "    cleaned_count = 0\n",
        "    for i, row in enumerate(rows):\n",
        "        original_pred = row.get('predict', '')\n",
        "\n",
        "        if len(original_pred) > cleaning_threshold:\n",
        "            cleaned_pred = extract_keywords_from_prediction(original_pred)\n",
        "            row['cleaned_predict'] = cleaned_pred\n",
        "            row['original_predict_length'] = len(original_pred)\n",
        "            cleaned_count += 1\n",
        "\n",
        "            # 显示前几个清理示例\n",
        "            if i < 3:\n",
        "                print(f\"\\nSample {i}:\")\n",
        "                print(f\"  Original: {original_pred[:100]}...\")\n",
        "                print(f\"  Cleaned:  {cleaned_pred}\")\n",
        "                print(f\"  Gold:     {row.get('label', '')}\")\n",
        "        else:\n",
        "            row['cleaned_predict'] = original_pred\n",
        "            row['original_predict_length'] = len(original_pred)\n",
        "\n",
        "    print(f\"Cleaned {cleaned_count} long predictions (>{cleaning_threshold} chars)\")\n",
        "\n",
        "    # === 第二步：计算传统指标 ===\n",
        "    print(f\"\\n=== Step 2: Computing Traditional Metrics ===\")\n",
        "\n",
        "    # 原始预测指标\n",
        "    original_anls_list, original_em_list, original_f1_list = [], [], []\n",
        "    # 清理后预测指标\n",
        "    cleaned_anls_list, cleaned_em_list, cleaned_f1_list = [], [], []\n",
        "\n",
        "    improvement_cases = []\n",
        "\n",
        "    for row in rows:\n",
        "        original_pred = row.get('predict', '')\n",
        "        cleaned_pred = row.get('cleaned_predict', '')\n",
        "        gold = row.get('label', '')\n",
        "\n",
        "        # 原始指标\n",
        "        orig_anls = anls_single(original_pred, gold)\n",
        "        orig_em = exact_match(original_pred, gold)\n",
        "        orig_f1 = f1_token_level(original_pred, gold)\n",
        "\n",
        "        # 清理后指标\n",
        "        clean_anls = anls_single(cleaned_pred, gold)\n",
        "        clean_em = exact_match(cleaned_pred, gold)\n",
        "        clean_f1 = f1_token_level(cleaned_pred, gold)\n",
        "\n",
        "        # 保存到row中\n",
        "        row['original_anls'] = orig_anls\n",
        "        row['original_em'] = orig_em\n",
        "        row['original_f1'] = orig_f1\n",
        "        row['cleaned_anls'] = clean_anls\n",
        "        row['cleaned_em'] = clean_em\n",
        "        row['cleaned_f1'] = clean_f1\n",
        "\n",
        "        original_anls_list.append(orig_anls)\n",
        "        original_em_list.append(orig_em)\n",
        "        original_f1_list.append(orig_f1)\n",
        "        cleaned_anls_list.append(clean_anls)\n",
        "        cleaned_em_list.append(clean_em)\n",
        "        cleaned_f1_list.append(clean_f1)\n",
        "\n",
        "        # 记录改进案例\n",
        "        if clean_em > orig_em or clean_f1 > orig_f1:\n",
        "            improvement_cases.append({\n",
        "                'original': original_pred[:80],\n",
        "                'cleaned': cleaned_pred,\n",
        "                'gold': gold,\n",
        "                'orig_em': orig_em,\n",
        "                'clean_em': clean_em,\n",
        "                'orig_f1': orig_f1,\n",
        "                'clean_f1': clean_f1\n",
        "            })\n",
        "\n",
        "    # === 第三步：计算Reranker分数 ===\n",
        "    print(f\"\\n=== Step 3: Computing Reranker Scores ===\")\n",
        "\n",
        "    original_rer_list = []\n",
        "    cleaned_rer_list = []\n",
        "\n",
        "    if predict_fn:\n",
        "        # 准备原始预测的pairs\n",
        "        original_pairs = []\n",
        "        cleaned_pairs = []\n",
        "\n",
        "        for row in rows:\n",
        "            question = extract_question_from_prompt(row.get('prompt', ''))\n",
        "            original_pred = row.get('predict', '')\n",
        "            cleaned_pred = row.get('cleaned_predict', '')\n",
        "\n",
        "            if question and original_pred:\n",
        "                original_pairs.append((normalize_text(question), normalize_text(original_pred)))\n",
        "            if question and cleaned_pred:\n",
        "                cleaned_pairs.append((normalize_text(question), normalize_text(cleaned_pred)))\n",
        "\n",
        "        print(f\"Computing reranker scores for {len(original_pairs)} original pairs...\")\n",
        "        try:\n",
        "            original_scores = predict_fn(original_pairs)\n",
        "            for i, (row, score) in enumerate(zip(rows[:len(original_scores)], original_scores)):\n",
        "                if isinstance(score, (list, tuple)):\n",
        "                    score = score[0] if score else 0.0\n",
        "                row['original_reranker_score'] = float(score)\n",
        "                original_rer_list.append(float(score))\n",
        "        except Exception as e:\n",
        "            print(f\"Original reranker computation failed: {e}\")\n",
        "\n",
        "        print(f\"Computing reranker scores for {len(cleaned_pairs)} cleaned pairs...\")\n",
        "        try:\n",
        "            cleaned_scores = predict_fn(cleaned_pairs)\n",
        "            for i, (row, score) in enumerate(zip(rows[:len(cleaned_scores)], cleaned_scores)):\n",
        "                if isinstance(score, (list, tuple)):\n",
        "                    score = score[0] if score else 0.0\n",
        "                row['cleaned_reranker_score'] = float(score)\n",
        "                cleaned_rer_list.append(float(score))\n",
        "        except Exception as e:\n",
        "            print(f\"Cleaned reranker computation failed: {e}\")\n",
        "\n",
        "    # === 第四步：汇总结果 ===\n",
        "    print(f\"\\n=== Step 4: Results Summary ===\")\n",
        "\n",
        "    metrics = {\n",
        "        'total_samples': len(rows),\n",
        "        'cleaned_predictions': cleaned_count,\n",
        "        'cleaning_threshold': cleaning_threshold,\n",
        "\n",
        "        # 传统指标对比\n",
        "        'original_anls_mean': np.mean(original_anls_list),\n",
        "        'cleaned_anls_mean': np.mean(cleaned_anls_list),\n",
        "        'anls_improvement': np.mean(cleaned_anls_list) - np.mean(original_anls_list),\n",
        "\n",
        "        'original_em_mean': np.mean(original_em_list),\n",
        "        'cleaned_em_mean': np.mean(cleaned_em_list),\n",
        "        'em_improvement': np.mean(cleaned_em_list) - np.mean(original_em_list),\n",
        "\n",
        "        'original_f1_mean': np.mean(original_f1_list),\n",
        "        'cleaned_f1_mean': np.mean(cleaned_f1_list),\n",
        "        'f1_improvement': np.mean(cleaned_f1_list) - np.mean(original_f1_list),\n",
        "\n",
        "        'improved_cases': len(improvement_cases),\n",
        "\n",
        "        # Reranker指标\n",
        "        'reranker_model': rer_model,\n",
        "    }\n",
        "\n",
        "    if original_rer_list:\n",
        "        metrics.update({\n",
        "            'original_reranker_mean': np.mean(original_rer_list),\n",
        "            'original_reranker_std': np.std(original_rer_list),\n",
        "        })\n",
        "\n",
        "    if cleaned_rer_list:\n",
        "        metrics.update({\n",
        "            'cleaned_reranker_mean': np.mean(cleaned_rer_list),\n",
        "            'cleaned_reranker_std': np.std(cleaned_rer_list),\n",
        "            'reranker_improvement': np.mean(cleaned_rer_list) - np.mean(original_rer_list) if original_rer_list else 0,\n",
        "        })\n",
        "\n",
        "    # 显示结果\n",
        "    print(\"Results:\")\n",
        "    print(f\"  Original ANLS: {metrics['original_anls_mean']:.4f}\")\n",
        "    print(f\"  Cleaned ANLS:  {metrics['cleaned_anls_mean']:.4f}\")\n",
        "    print(f\"  ANLS Improvement: {metrics['anls_improvement']:.4f}\")\n",
        "    print(f\"  Original EM: {metrics['original_em_mean']:.4f}\")\n",
        "    print(f\"  Cleaned EM:  {metrics['cleaned_em_mean']:.4f}\")\n",
        "    print(f\"  EM Improvement: {metrics['em_improvement']:.4f}\")\n",
        "    print(f\"  Original F1: {metrics['original_f1_mean']:.4f}\")\n",
        "    print(f\"  Cleaned F1:  {metrics['cleaned_f1_mean']:.4f}\")\n",
        "    print(f\"  F1 Improvement: {metrics['f1_improvement']:.4f}\")\n",
        "\n",
        "    if original_rer_list and cleaned_rer_list:\n",
        "        print(f\"  Original Reranker: {metrics['original_reranker_mean']:.4f}\")\n",
        "        print(f\"  Cleaned Reranker:  {metrics['cleaned_reranker_mean']:.4f}\")\n",
        "        print(f\"  Reranker Improvement: {metrics['reranker_improvement']:.4f}\")\n",
        "\n",
        "    print(f\"  Improved cases: {metrics['improved_cases']}\")\n",
        "\n",
        "    # 显示改进案例\n",
        "    print(f\"\\n=== Top Improvement Cases ===\")\n",
        "    for i, case in enumerate(improvement_cases[:3]):\n",
        "        print(f\"Case {i+1}:\")\n",
        "        print(f\"  Original: {case['original']}...\")\n",
        "        print(f\"  Cleaned:  {case['cleaned']}\")\n",
        "        print(f\"  Gold:     {case['gold']}\")\n",
        "        print(f\"  EM: {case['orig_em']} -> {case['clean_em']}\")\n",
        "        print(f\"  F1: {case['orig_f1']:.3f} -> {case['clean_f1']:.3f}\")\n",
        "        print()\n",
        "\n",
        "    # === 保存结果 ===\n",
        "    output_path = input_path.replace('.jsonl', '_comprehensive_results.jsonl')\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        for row in rows:\n",
        "            f.write(json.dumps(row, ensure_ascii=False) + '\\n')\n",
        "\n",
        "    metrics_path = input_path.replace('.jsonl', '_comprehensive_metrics.json')\n",
        "    with open(metrics_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"\\nSaved detailed results to: {output_path}\")\n",
        "    print(f\"Saved metrics to: {metrics_path}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 运行综合评估\n",
        "    input_file = \"/content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infovblastest/generated_predictions.jsonl\"\n",
        "\n",
        "    # 参数说明：\n",
        "    # reranker_kind: \"mini\", \"bge\", 或 \"none\"\n",
        "    # cleaning_threshold: 超过这个字符数的预测会被清理，默认200\n",
        "    results = comprehensive_evaluate_with_cleaning_and_reranker(\n",
        "        input_file,\n",
        "        reranker_kind=\"bge\",\n",
        "        cleaning_threshold=200\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWX-fkeB7q3Q",
        "outputId": "68514fb5-fab6-46c6-9923-311952bf7132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Comprehensive Evaluation: Cleaning + Reranker ===\n",
            "Loading data from: /content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infovblastest/generated_predictions.jsonl\n",
            "Total samples: 535\n",
            "\n",
            "=== Step 1: Cleaning Predictions ===\n",
            "\n",
            "Sample 0:\n",
            "  Original: Pinterest Pinterest, Pinterest, Pinterest[2] Pinterest, Pinterest, Pinterest is a social media platf...\n",
            "  Cleaned:  pinterest\n",
            "  Gold:     pinterest\n",
            "\n",
            "\n",
            "Sample 1:\n",
            "  Original: Rest: Social media platform cheat sheet, Social media platform cheat sheet, Retail, Nonprofits, News...\n",
            "  Cleaned:  Social, media, platform\n",
            "  Gold:     restaurants, interior design, wedding venues\n",
            "\n",
            "\n",
            "Sample 2:\n",
            "  Original: Facebook, Instagram, Instagram, Instagram is good for B2B companies, Instagram, Instagram is good fo...\n",
            "  Cleaned:  facebook\n",
            "  Gold:     linkedin, facebook\n",
            "\n",
            "Cleaned 126 long predictions (>200 chars)\n",
            "\n",
            "=== Step 2: Computing Traditional Metrics ===\n",
            "\n",
            "=== Step 3: Computing Reranker Scores ===\n",
            "Computing reranker scores for 469 original pairs...\n",
            "Computing reranker scores for 469 cleaned pairs...\n",
            "\n",
            "=== Step 4: Results Summary ===\n",
            "Results:\n",
            "  Original ANLS: 0.0015\n",
            "  Cleaned ANLS:  0.0344\n",
            "  ANLS Improvement: 0.0329\n",
            "  Original EM: 0.0000\n",
            "  Cleaned EM:  0.0187\n",
            "  EM Improvement: 0.0187\n",
            "  Original F1: 0.0344\n",
            "  Cleaned F1:  0.0648\n",
            "  F1 Improvement: 0.0304\n",
            "  Original Reranker: 0.4866\n",
            "  Cleaned Reranker:  0.3682\n",
            "  Reranker Improvement: -0.1184\n",
            "  Improved cases: 38\n",
            "\n",
            "=== Top Improvement Cases ===\n",
            "Case 1:\n",
            "  Original: Pinterest Pinterest, Pinterest, Pinterest[2] Pinterest, Pinterest, Pinterest is ...\n",
            "  Cleaned:  pinterest\n",
            "  Gold:     pinterest\n",
            "\n",
            "  EM: 0 -> 1\n",
            "  F1: 0.059 -> 1.000\n",
            "\n",
            "Case 2:\n",
            "  Original: Facebook, Instagram, Instagram, Instagram is good for B2B companies, Instagram, ...\n",
            "  Cleaned:  facebook\n",
            "  Gold:     linkedin, facebook\n",
            "\n",
            "  EM: 0 -> 0\n",
            "  F1: 0.061 -> 0.667\n",
            "\n",
            "Case 3:\n",
            "  Original: LinkedIn, LinkedIn, LinkedIn, LinkedInthe platform, LinkedIn, LinkedIn, LinkedIn...\n",
            "  Cleaned:  linkedin\n",
            "  Gold:     linkedin\n",
            "\n",
            "  EM: 0 -> 1\n",
            "  F1: 0.077 -> 1.000\n",
            "\n",
            "\n",
            "Saved detailed results to: /content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infovblastest/generated_predictions_comprehensive_results.jsonl\n",
            "Saved metrics to: /content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infovblastest/generated_predictions_comprehensive_metrics.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"安全的sigmoid函数\"\"\"\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "\n",
        "def load_reranker(kind=\"mini\"):\n",
        "    \"\"\"加载reranker模型\"\"\"\n",
        "    if kind == \"none\":\n",
        "        return None, None\n",
        "    if kind == \"mini\":\n",
        "        from sentence_transformers import CrossEncoder\n",
        "        model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "        def predict_fn(pairs):\n",
        "            raw_scores = model.predict(pairs)\n",
        "            sigmoid_scores = sigmoid(np.array(raw_scores))\n",
        "            return sigmoid_scores.tolist()\n",
        "        return predict_fn, \"ms-marco-MiniLM\"\n",
        "    elif kind == \"bge\":\n",
        "        from FlagEmbedding import FlagReranker\n",
        "        import torch\n",
        "        rr = FlagReranker(\"BAAI/bge-reranker-large\", use_fp16=True)\n",
        "        def predict_fn(pairs):\n",
        "            scores = rr.compute_score(pairs)\n",
        "            if isinstance(scores, torch.Tensor):\n",
        "                scores = scores.sigmoid().tolist()\n",
        "            else:\n",
        "                scores = sigmoid(np.array(scores)).tolist()\n",
        "            return scores\n",
        "        return predict_fn, \"bge-reranker-large\"\n",
        "\n",
        "def extract_keywords_from_prediction(prediction: str, top_n=5) -> str:\n",
        "    \"\"\"从冗长的预测中提取关键词\"\"\"\n",
        "    if not prediction:\n",
        "        return \"\"\n",
        "\n",
        "    # 1. 清理文本\n",
        "    text = prediction.lower()\n",
        "\n",
        "    # 2. 移除重复的句子片段\n",
        "    sentences = re.split(r'[.!?]\\s*', text)\n",
        "    unique_sentences = []\n",
        "    seen = set()\n",
        "    for sent in sentences:\n",
        "        sent = sent.strip()\n",
        "        if sent and sent not in seen and len(sent) > 10:\n",
        "            seen.add(sent)\n",
        "            unique_sentences.append(sent)\n",
        "\n",
        "    # 3. 提取候选关键词\n",
        "    candidates = []\n",
        "\n",
        "    # 方法1: 提取开头的词汇（通常是答案）\n",
        "    first_words = re.findall(r'\\b[a-zA-Z]+\\b', prediction[:200])\n",
        "    candidates.extend(first_words[:10])\n",
        "\n",
        "    # 方法2: 提取品牌/平台名称\n",
        "    platform_keywords = [\n",
        "        'pinterest', 'facebook', 'instagram', 'linkedin', 'twitter',\n",
        "        'youtube', 'tiktok', 'snapchat', 'whatsapp', 'telegram',\n",
        "        'restaurants', 'interior design', 'wedding venues', 'fashion',\n",
        "        'food', 'travel', 'photography', 'art', 'design', 'business',\n",
        "        'home', 'decor', 'style', 'beauty', 'fitness', 'health'\n",
        "    ]\n",
        "\n",
        "    for keyword in platform_keywords:\n",
        "        if keyword in text:\n",
        "            candidates.append(keyword)\n",
        "\n",
        "    # 方法3: 提取逗号分隔的词汇\n",
        "    comma_separated = re.findall(r'\\b[a-zA-Z\\s]+(?=,|\\.|$)', text[:300])\n",
        "    for item in comma_separated:\n",
        "        item = item.strip()\n",
        "        if item and len(item.split()) <= 3:  # 最多3个词\n",
        "            candidates.append(item)\n",
        "\n",
        "    # 4. 统计词频并选择最佳答案\n",
        "    word_counts = Counter()\n",
        "    for candidate in candidates:\n",
        "        if candidate and len(candidate) > 1:\n",
        "            clean_candidate = re.sub(r'[^\\w\\s,]', '', candidate).strip()\n",
        "            if clean_candidate:\n",
        "                word_counts[clean_candidate] += 1\n",
        "\n",
        "    # 5. 选择最频繁的关键词\n",
        "    if word_counts:\n",
        "        # 优先选择平台关键词\n",
        "        for keyword in platform_keywords:\n",
        "            if keyword in word_counts:\n",
        "                return keyword\n",
        "\n",
        "        # 否则选择最频繁的词\n",
        "        most_common = word_counts.most_common(top_n)\n",
        "        best_candidates = [word for word, count in most_common if count >= 1]\n",
        "\n",
        "        if best_candidates:\n",
        "            return ', '.join(best_candidates[:3])  # 最多3个关键词\n",
        "\n",
        "    # 6. 如果都失败，返回前几个有意义的词\n",
        "    words = re.findall(r'\\b[a-zA-Z]+\\b', prediction[:100])\n",
        "    meaningful_words = [w for w in words if len(w) > 2 and w.lower() not in\n",
        "                       ['the', 'and', 'for', 'are', 'this', 'that', 'with', 'have', 'will']]\n",
        "\n",
        "    if meaningful_words:\n",
        "        return ', '.join(meaningful_words[:3])\n",
        "\n",
        "    return prediction[:50].strip()  # 最后的备选方案\n",
        "\n",
        "def extract_question_from_prompt(prompt: str) -> str:\n",
        "    \"\"\"从prompt中提取问题\"\"\"\n",
        "    if not isinstance(prompt, str):\n",
        "        return \"\"\n",
        "    m = re.search(r\"<\\|vision_end\\|>(.*)<\\|im_end\\|>\", prompt, re.DOTALL)\n",
        "    if m:\n",
        "        q = m.group(1)\n",
        "    else:\n",
        "        m2 = re.findall(r\"<\\|im_start\\|>user(.*)<\\|im_end\\|>\", prompt, re.DOTALL)\n",
        "        q = m2[-1] if m2 else \"\"\n",
        "    q = q.replace(\"\\r\",\" \").replace(\"\\n\",\" \")\n",
        "    while \"  \" in q:\n",
        "        q = q.replace(\"  \", \" \")\n",
        "    return q.strip()\n",
        "\n",
        "def normalize_text(s: str) -> str:\n",
        "    if s is None: return \"\"\n",
        "    s = str(s).strip().lower().replace(\"\\u00A0\",\" \").replace(\"\\t\",\" \")\n",
        "    while \"  \" in s: s = s.replace(\"  \",\" \")\n",
        "    return s\n",
        "\n",
        "def simple_tokenize(s: str):\n",
        "    s = normalize_text(s)\n",
        "    return s.split() if s else []\n",
        "\n",
        "def edit_distance(a: str, b: str) -> int:\n",
        "    na, nb = len(a), len(b)\n",
        "    if na==0: return nb\n",
        "    if nb==0: return na\n",
        "    prev = list(range(nb+1)); curr=[0]*(nb+1)\n",
        "    for i in range(1,na+1):\n",
        "        curr[0]=i; ca=a[i-1]\n",
        "        for j in range(1,nb+1):\n",
        "            cb=b[j-1]; cost=0 if ca==cb else 1\n",
        "            curr[j]=min(prev[j]+1, curr[j-1]+1, prev[j-1]+cost)\n",
        "        prev, curr = curr, prev\n",
        "    return prev[nb]\n",
        "\n",
        "def anls_single(pred: str, gold: str) -> float:\n",
        "    pred, gold = normalize_text(pred), normalize_text(gold)\n",
        "    if pred==\"\" and gold==\"\": return 1.0\n",
        "    if pred==\"\" or gold==\"\":  return 0.0\n",
        "    d = edit_distance(pred, gold)\n",
        "    denom = max(len(pred), len(gold))\n",
        "    if denom==0: return 0.0\n",
        "    norm = d/denom\n",
        "    return (1.0-norm) if norm<0.5 else 0.0\n",
        "\n",
        "def exact_match(pred: str, gold: str) -> int:\n",
        "    return int(normalize_text(pred) == normalize_text(gold))\n",
        "\n",
        "def f1_token_level(pred: str, gold: str) -> float:\n",
        "    p = simple_tokenize(pred); g = simple_tokenize(gold)\n",
        "    if not p and not g: return 1.0\n",
        "    if not p or not g:  return 0.0\n",
        "\n",
        "    pc, gc = Counter(p), Counter(g)\n",
        "    overlap = sum((pc & gc).values())\n",
        "    if overlap==0: return 0.0\n",
        "    precision, recall = overlap/len(p), overlap/len(g)\n",
        "    return 2*precision*recall/(precision+recall)\n",
        "\n",
        "def comprehensive_evaluate_with_cleaning_and_reranker(input_path: str, reranker_kind=\"mini\", cleaning_threshold=200):\n",
        "    \"\"\"整合清理和reranker的综合评估\"\"\"\n",
        "    print(\"=== Comprehensive Evaluation: Cleaning + Reranker ===\")\n",
        "\n",
        "    # 加载reranker\n",
        "    predict_fn, rer_model = load_reranker(reranker_kind) if reranker_kind != \"none\" else (None, None)\n",
        "\n",
        "    # 读取数据\n",
        "    print(f\"Loading data from: {input_path}\")\n",
        "    rows = []\n",
        "    with open(input_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                rows.append(json.loads(line))\n",
        "\n",
        "    print(f\"Total samples: {len(rows)}\")\n",
        "\n",
        "    # === 第一步：清理预测 ===\n",
        "    print(f\"\\n=== Step 1: Cleaning Predictions ===\")\n",
        "    cleaned_count = 0\n",
        "    for i, row in enumerate(rows):\n",
        "        original_pred = row.get('predict', '')\n",
        "\n",
        "        if len(original_pred) > cleaning_threshold:\n",
        "            cleaned_pred = extract_keywords_from_prediction(original_pred)\n",
        "            row['cleaned_predict'] = cleaned_pred\n",
        "            row['original_predict_length'] = len(original_pred)\n",
        "            cleaned_count += 1\n",
        "\n",
        "            # 显示前几个清理示例\n",
        "            if i < 3:\n",
        "                print(f\"\\nSample {i}:\")\n",
        "                print(f\"  Original: {original_pred[:100]}...\")\n",
        "                print(f\"  Cleaned:  {cleaned_pred}\")\n",
        "                print(f\"  Gold:     {row.get('label', '')}\")\n",
        "        else:\n",
        "            row['cleaned_predict'] = original_pred\n",
        "            row['original_predict_length'] = len(original_pred)\n",
        "\n",
        "    print(f\"Cleaned {cleaned_count} long predictions (>{cleaning_threshold} chars)\")\n",
        "\n",
        "    # === 第二步：计算传统指标 ===\n",
        "    print(f\"\\n=== Step 2: Computing Traditional Metrics ===\")\n",
        "\n",
        "    # 原始预测指标\n",
        "    original_anls_list, original_em_list, original_f1_list = [], [], []\n",
        "    # 清理后预测指标\n",
        "    cleaned_anls_list, cleaned_em_list, cleaned_f1_list = [], [], []\n",
        "\n",
        "    improvement_cases = []\n",
        "\n",
        "    for row in rows:\n",
        "        original_pred = row.get('predict', '')\n",
        "        cleaned_pred = row.get('cleaned_predict', '')\n",
        "        gold = row.get('label', '')\n",
        "\n",
        "        # 原始指标\n",
        "        orig_anls = anls_single(original_pred, gold)\n",
        "        orig_em = exact_match(original_pred, gold)\n",
        "        orig_f1 = f1_token_level(original_pred, gold)\n",
        "\n",
        "        # 清理后指标\n",
        "        clean_anls = anls_single(cleaned_pred, gold)\n",
        "        clean_em = exact_match(cleaned_pred, gold)\n",
        "        clean_f1 = f1_token_level(cleaned_pred, gold)\n",
        "\n",
        "        # 保存到row中\n",
        "        row['original_anls'] = orig_anls\n",
        "        row['original_em'] = orig_em\n",
        "        row['original_f1'] = orig_f1\n",
        "        row['cleaned_anls'] = clean_anls\n",
        "        row['cleaned_em'] = clean_em\n",
        "        row['cleaned_f1'] = clean_f1\n",
        "\n",
        "        original_anls_list.append(orig_anls)\n",
        "        original_em_list.append(orig_em)\n",
        "        original_f1_list.append(orig_f1)\n",
        "        cleaned_anls_list.append(clean_anls)\n",
        "        cleaned_em_list.append(clean_em)\n",
        "        cleaned_f1_list.append(clean_f1)\n",
        "\n",
        "        # 记录改进案例\n",
        "        if clean_em > orig_em or clean_f1 > orig_f1:\n",
        "            improvement_cases.append({\n",
        "                'original': original_pred[:80],\n",
        "                'cleaned': cleaned_pred,\n",
        "                'gold': gold,\n",
        "                'orig_em': orig_em,\n",
        "                'clean_em': clean_em,\n",
        "                'orig_f1': orig_f1,\n",
        "                'clean_f1': clean_f1\n",
        "            })\n",
        "\n",
        "    # === 第三步：计算Reranker分数 ===\n",
        "    print(f\"\\n=== Step 3: Computing Reranker Scores ===\")\n",
        "\n",
        "    original_rer_list = []\n",
        "    cleaned_rer_list = []\n",
        "\n",
        "    if predict_fn:\n",
        "        # 准备原始预测的pairs\n",
        "        original_pairs = []\n",
        "        cleaned_pairs = []\n",
        "\n",
        "        for row in rows:\n",
        "            question = extract_question_from_prompt(row.get('prompt', ''))\n",
        "            original_pred = row.get('predict', '')\n",
        "            cleaned_pred = row.get('cleaned_predict', '')\n",
        "\n",
        "            if question and original_pred:\n",
        "                original_pairs.append((normalize_text(question), normalize_text(original_pred)))\n",
        "            if question and cleaned_pred:\n",
        "                cleaned_pairs.append((normalize_text(question), normalize_text(cleaned_pred)))\n",
        "\n",
        "        print(f\"Computing reranker scores for {len(original_pairs)} original pairs...\")\n",
        "        try:\n",
        "            original_scores = predict_fn(original_pairs)\n",
        "            for i, (row, score) in enumerate(zip(rows[:len(original_scores)], original_scores)):\n",
        "                if isinstance(score, (list, tuple)):\n",
        "                    score = score[0] if score else 0.0\n",
        "                row['original_reranker_score'] = float(score)\n",
        "                original_rer_list.append(float(score))\n",
        "        except Exception as e:\n",
        "            print(f\"Original reranker computation failed: {e}\")\n",
        "\n",
        "        print(f\"Computing reranker scores for {len(cleaned_pairs)} cleaned pairs...\")\n",
        "        try:\n",
        "            cleaned_scores = predict_fn(cleaned_pairs)\n",
        "            for i, (row, score) in enumerate(zip(rows[:len(cleaned_scores)], cleaned_scores)):\n",
        "                if isinstance(score, (list, tuple)):\n",
        "                    score = score[0] if score else 0.0\n",
        "                row['cleaned_reranker_score'] = float(score)\n",
        "                cleaned_rer_list.append(float(score))\n",
        "        except Exception as e:\n",
        "            print(f\"Cleaned reranker computation failed: {e}\")\n",
        "\n",
        "    # === 第四步：汇总结果 ===\n",
        "    print(f\"\\n=== Step 4: Results Summary ===\")\n",
        "\n",
        "    metrics = {\n",
        "        'total_samples': len(rows),\n",
        "        'cleaned_predictions': cleaned_count,\n",
        "        'cleaning_threshold': cleaning_threshold,\n",
        "\n",
        "        # 传统指标对比\n",
        "        'original_anls_mean': np.mean(original_anls_list),\n",
        "        'cleaned_anls_mean': np.mean(cleaned_anls_list),\n",
        "        'anls_improvement': np.mean(cleaned_anls_list) - np.mean(original_anls_list),\n",
        "\n",
        "        'original_em_mean': np.mean(original_em_list),\n",
        "        'cleaned_em_mean': np.mean(cleaned_em_list),\n",
        "        'em_improvement': np.mean(cleaned_em_list) - np.mean(original_em_list),\n",
        "\n",
        "        'original_f1_mean': np.mean(original_f1_list),\n",
        "        'cleaned_f1_mean': np.mean(cleaned_f1_list),\n",
        "        'f1_improvement': np.mean(cleaned_f1_list) - np.mean(original_f1_list),\n",
        "\n",
        "        'improved_cases': len(improvement_cases),\n",
        "\n",
        "        # Reranker指标\n",
        "        'reranker_model': rer_model,\n",
        "    }\n",
        "\n",
        "    if original_rer_list:\n",
        "        metrics.update({\n",
        "            'original_reranker_mean': np.mean(original_rer_list),\n",
        "            'original_reranker_std': np.std(original_rer_list),\n",
        "        })\n",
        "\n",
        "    if cleaned_rer_list:\n",
        "        metrics.update({\n",
        "            'cleaned_reranker_mean': np.mean(cleaned_rer_list),\n",
        "            'cleaned_reranker_std': np.std(cleaned_rer_list),\n",
        "            'reranker_improvement': np.mean(cleaned_rer_list) - np.mean(original_rer_list) if original_rer_list else 0,\n",
        "        })\n",
        "\n",
        "    # 显示结果\n",
        "    print(\"Results:\")\n",
        "    print(f\"  Original ANLS: {metrics['original_anls_mean']:.4f}\")\n",
        "    print(f\"  Cleaned ANLS:  {metrics['cleaned_anls_mean']:.4f}\")\n",
        "    print(f\"  ANLS Improvement: {metrics['anls_improvement']:.4f}\")\n",
        "    print(f\"  Original EM: {metrics['original_em_mean']:.4f}\")\n",
        "    print(f\"  Cleaned EM:  {metrics['cleaned_em_mean']:.4f}\")\n",
        "    print(f\"  EM Improvement: {metrics['em_improvement']:.4f}\")\n",
        "    print(f\"  Original F1: {metrics['original_f1_mean']:.4f}\")\n",
        "    print(f\"  Cleaned F1:  {metrics['cleaned_f1_mean']:.4f}\")\n",
        "    print(f\"  F1 Improvement: {metrics['f1_improvement']:.4f}\")\n",
        "\n",
        "    if original_rer_list and cleaned_rer_list:\n",
        "        print(f\"  Original Reranker: {metrics['original_reranker_mean']:.4f}\")\n",
        "        print(f\"  Cleaned Reranker:  {metrics['cleaned_reranker_mean']:.4f}\")\n",
        "        print(f\"  Reranker Improvement: {metrics['reranker_improvement']:.4f}\")\n",
        "\n",
        "    print(f\"  Improved cases: {metrics['improved_cases']}\")\n",
        "\n",
        "    # 显示改进案例\n",
        "    print(f\"\\n=== Top Improvement Cases ===\")\n",
        "    for i, case in enumerate(improvement_cases[:3]):\n",
        "        print(f\"Case {i+1}:\")\n",
        "        print(f\"  Original: {case['original']}...\")\n",
        "        print(f\"  Cleaned:  {case['cleaned']}\")\n",
        "        print(f\"  Gold:     {case['gold']}\")\n",
        "        print(f\"  EM: {case['orig_em']} -> {case['clean_em']}\")\n",
        "        print(f\"  F1: {case['orig_f1']:.3f} -> {case['clean_f1']:.3f}\")\n",
        "        print()\n",
        "\n",
        "    # === 保存结果 ===\n",
        "    output_path = input_path.replace('.jsonl', '_comprehensive_results.jsonl')\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        for row in rows:\n",
        "            f.write(json.dumps(row, ensure_ascii=False) + '\\n')\n",
        "\n",
        "    metrics_path = input_path.replace('.jsonl', '_comprehensive_metrics.json')\n",
        "    with open(metrics_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"\\nSaved detailed results to: {output_path}\")\n",
        "    print(f\"Saved metrics to: {metrics_path}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 运行综合评估\n",
        "    input_file = \"/content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infovblastest/generated_predictions.jsonl\"\n",
        "\n",
        "    # 参数说明：\n",
        "    # reranker_kind: \"mini\", \"bge\", 或 \"none\"\n",
        "    # cleaning_threshold: 超过这个字符数的预测会被清理，默认200\n",
        "    results = comprehensive_evaluate_with_cleaning_and_reranker(\n",
        "        input_file,\n",
        "        reranker_kind=\"mini\",\n",
        "        cleaning_threshold=200\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-eke-hLtUiB"
      },
      "source": [
        "infobase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3bp_xgp7ool"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L807m0y7nfQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak6gE1Hi7mpJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFsSv_o70ENU",
        "outputId": "f2ae680f-80ca-4f18-ef8b-1de6b4b38b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Comprehensive Evaluation: Cleaning + Reranker ===\n",
            "Loading data from: /content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infobaseloratest/generated_predictions.jsonl\n",
            "Total samples: 535\n",
            "\n",
            "=== Step 1: Cleaning Predictions ===\n",
            "\n",
            "Sample 2:\n",
            "  Original: The two platforms that are good for B2B companies are LinkedIn and Facebook. LinkedIn is a professio...\n",
            "  Cleaned:  facebook\n",
            "  Gold:     linkedin, facebook\n",
            "\n",
            "Cleaned 53 long predictions (>200 chars)\n",
            "\n",
            "=== Step 2: Computing Traditional Metrics ===\n",
            "\n",
            "=== Step 3: Computing Reranker Scores ===\n",
            "Computing reranker scores for 245 original pairs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "pre tokenize:   0%|          | 0/2 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "pre tokenize: 100%|██████████| 2/2 [00:00<00:00, 95.82it/s]\n",
            "Compute Scores: 100%|██████████| 2/2 [00:00<00:00, 17.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing reranker scores for 245 cleaned pairs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "pre tokenize: 100%|██████████| 2/2 [00:00<00:00, 118.42it/s]\n",
            "Compute Scores: 100%|██████████| 2/2 [00:00<00:00, 22.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Step 4: Results Summary ===\n",
            "Results:\n",
            "  Original ANLS: 0.0000\n",
            "  Cleaned ANLS:  0.0019\n",
            "  ANLS Improvement: 0.0019\n",
            "  Original EM: 0.0000\n",
            "  Cleaned EM:  0.0019\n",
            "  EM Improvement: 0.0019\n",
            "  Original F1: 0.0091\n",
            "  Cleaned F1:  0.0089\n",
            "  F1 Improvement: -0.0002\n",
            "  Original Reranker: 0.4393\n",
            "  Cleaned Reranker:  0.3108\n",
            "  Reranker Improvement: -0.1286\n",
            "  Improved cases: 2\n",
            "\n",
            "=== Top Improvement Cases ===\n",
            "Case 1:\n",
            "  Original: The two platforms that are good for B2B companies are LinkedIn and Facebook. Lin...\n",
            "  Cleaned:  facebook\n",
            "  Gold:     linkedin, facebook\n",
            "\n",
            "  EM: 0 -> 0\n",
            "  F1: 0.000 -> 0.667\n",
            "\n",
            "Case 2:\n",
            "  Original: Based-on@nefertiti\n",
            "The platform suitable for software providers is LinkedIn. Thi...\n",
            "  Cleaned:  linkedin\n",
            "  Gold:     linkedin\n",
            "\n",
            "  EM: 0 -> 1\n",
            "  F1: 0.051 -> 1.000\n",
            "\n",
            "\n",
            "Saved detailed results to: /content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infobaseloratest/generated_predictions_comprehensive_results.jsonl\n",
            "Saved metrics to: /content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infobaseloratest/generated_predictions_comprehensive_metrics.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"安全的sigmoid函数\"\"\"\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "\n",
        "def load_reranker(kind=\"mini\"):\n",
        "    \"\"\"加载reranker模型\"\"\"\n",
        "    if kind == \"none\":\n",
        "        return None, None\n",
        "    if kind == \"mini\":\n",
        "        from sentence_transformers import CrossEncoder\n",
        "        model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "        def predict_fn(pairs):\n",
        "            raw_scores = model.predict(pairs)\n",
        "            sigmoid_scores = sigmoid(np.array(raw_scores))\n",
        "            return sigmoid_scores.tolist()\n",
        "        return predict_fn, \"ms-marco-MiniLM\"\n",
        "    elif kind == \"bge\":\n",
        "        from FlagEmbedding import FlagReranker\n",
        "        import torch\n",
        "        rr = FlagReranker(\"BAAI/bge-reranker-large\", use_fp16=True)\n",
        "        def predict_fn(pairs):\n",
        "            scores = rr.compute_score(pairs)\n",
        "            if isinstance(scores, torch.Tensor):\n",
        "                scores = scores.sigmoid().tolist()\n",
        "            else:\n",
        "                scores = sigmoid(np.array(scores)).tolist()\n",
        "            return scores\n",
        "        return predict_fn, \"bge-reranker-large\"\n",
        "\n",
        "def extract_keywords_from_prediction(prediction: str, top_n=5) -> str:\n",
        "    \"\"\"从冗长的预测中提取关键词\"\"\"\n",
        "    if not prediction:\n",
        "        return \"\"\n",
        "\n",
        "    # 1. 清理文本\n",
        "    text = prediction.lower()\n",
        "\n",
        "    # 2. 移除重复的句子片段\n",
        "    sentences = re.split(r'[.!?]\\s*', text)\n",
        "    unique_sentences = []\n",
        "    seen = set()\n",
        "    for sent in sentences:\n",
        "        sent = sent.strip()\n",
        "        if sent and sent not in seen and len(sent) > 10:\n",
        "            seen.add(sent)\n",
        "            unique_sentences.append(sent)\n",
        "\n",
        "    # 3. 提取候选关键词\n",
        "    candidates = []\n",
        "\n",
        "    # 方法1: 提取开头的词汇（通常是答案）\n",
        "    first_words = re.findall(r'\\b[a-zA-Z]+\\b', prediction[:200])\n",
        "    candidates.extend(first_words[:10])\n",
        "\n",
        "    # 方法2: 提取品牌/平台名称\n",
        "    platform_keywords = [\n",
        "        'pinterest', 'facebook', 'instagram', 'linkedin', 'twitter',\n",
        "        'youtube', 'tiktok', 'snapchat', 'whatsapp', 'telegram',\n",
        "        'restaurants', 'interior design', 'wedding venues', 'fashion',\n",
        "        'food', 'travel', 'photography', 'art', 'design', 'business',\n",
        "        'home', 'decor', 'style', 'beauty', 'fitness', 'health'\n",
        "    ]\n",
        "\n",
        "    for keyword in platform_keywords:\n",
        "        if keyword in text:\n",
        "            candidates.append(keyword)\n",
        "\n",
        "    # 方法3: 提取逗号分隔的词汇\n",
        "    comma_separated = re.findall(r'\\b[a-zA-Z\\s]+(?=,|\\.|$)', text[:300])\n",
        "    for item in comma_separated:\n",
        "        item = item.strip()\n",
        "        if item and len(item.split()) <= 3:  # 最多3个词\n",
        "            candidates.append(item)\n",
        "\n",
        "    # 4. 统计词频并选择最佳答案\n",
        "    word_counts = Counter()\n",
        "    for candidate in candidates:\n",
        "        if candidate and len(candidate) > 1:\n",
        "            clean_candidate = re.sub(r'[^\\w\\s,]', '', candidate).strip()\n",
        "            if clean_candidate:\n",
        "                word_counts[clean_candidate] += 1\n",
        "\n",
        "    # 5. 选择最频繁的关键词\n",
        "    if word_counts:\n",
        "        # 优先选择平台关键词\n",
        "        for keyword in platform_keywords:\n",
        "            if keyword in word_counts:\n",
        "                return keyword\n",
        "\n",
        "        # 否则选择最频繁的词\n",
        "        most_common = word_counts.most_common(top_n)\n",
        "        best_candidates = [word for word, count in most_common if count >= 1]\n",
        "\n",
        "        if best_candidates:\n",
        "            return ', '.join(best_candidates[:3])  # 最多3个关键词\n",
        "\n",
        "    # 6. 如果都失败，返回前几个有意义的词\n",
        "    words = re.findall(r'\\b[a-zA-Z]+\\b', prediction[:100])\n",
        "    meaningful_words = [w for w in words if len(w) > 2 and w.lower() not in\n",
        "                       ['the', 'and', 'for', 'are', 'this', 'that', 'with', 'have', 'will']]\n",
        "\n",
        "    if meaningful_words:\n",
        "        return ', '.join(meaningful_words[:3])\n",
        "\n",
        "    return prediction[:50].strip()  # 最后的备选方案\n",
        "\n",
        "def extract_question_from_prompt(prompt: str) -> str:\n",
        "    \"\"\"从prompt中提取问题\"\"\"\n",
        "    if not isinstance(prompt, str):\n",
        "        return \"\"\n",
        "    m = re.search(r\"<\\|vision_end\\|>(.*)<\\|im_end\\|>\", prompt, re.DOTALL)\n",
        "    if m:\n",
        "        q = m.group(1)\n",
        "    else:\n",
        "        m2 = re.findall(r\"<\\|im_start\\|>user(.*)<\\|im_end\\|>\", prompt, re.DOTALL)\n",
        "        q = m2[-1] if m2 else \"\"\n",
        "    q = q.replace(\"\\r\",\" \").replace(\"\\n\",\" \")\n",
        "    while \"  \" in q:\n",
        "        q = q.replace(\"  \", \" \")\n",
        "    return q.strip()\n",
        "\n",
        "def normalize_text(s: str) -> str:\n",
        "    if s is None: return \"\"\n",
        "    s = str(s).strip().lower().replace(\"\\u00A0\",\" \").replace(\"\\t\",\" \")\n",
        "    while \"  \" in s: s = s.replace(\"  \",\" \")\n",
        "    return s\n",
        "\n",
        "def simple_tokenize(s: str):\n",
        "    s = normalize_text(s)\n",
        "    return s.split() if s else []\n",
        "\n",
        "def edit_distance(a: str, b: str) -> int:\n",
        "    na, nb = len(a), len(b)\n",
        "    if na==0: return nb\n",
        "    if nb==0: return na\n",
        "    prev = list(range(nb+1)); curr=[0]*(nb+1)\n",
        "    for i in range(1,na+1):\n",
        "        curr[0]=i; ca=a[i-1]\n",
        "        for j in range(1,nb+1):\n",
        "            cb=b[j-1]; cost=0 if ca==cb else 1\n",
        "            curr[j]=min(prev[j]+1, curr[j-1]+1, prev[j-1]+cost)\n",
        "        prev, curr = curr, prev\n",
        "    return prev[nb]\n",
        "\n",
        "def anls_single(pred: str, gold: str) -> float:\n",
        "    pred, gold = normalize_text(pred), normalize_text(gold)\n",
        "    if pred==\"\" and gold==\"\": return 1.0\n",
        "    if pred==\"\" or gold==\"\":  return 0.0\n",
        "    d = edit_distance(pred, gold)\n",
        "    denom = max(len(pred), len(gold))\n",
        "    if denom==0: return 0.0\n",
        "    norm = d/denom\n",
        "    return (1.0-norm) if norm<0.5 else 0.0\n",
        "\n",
        "def exact_match(pred: str, gold: str) -> int:\n",
        "    return int(normalize_text(pred) == normalize_text(gold))\n",
        "\n",
        "def f1_token_level(pred: str, gold: str) -> float:\n",
        "    p = simple_tokenize(pred); g = simple_tokenize(gold)\n",
        "    if not p and not g: return 1.0\n",
        "    if not p or not g:  return 0.0\n",
        "\n",
        "    pc, gc = Counter(p), Counter(g)\n",
        "    overlap = sum((pc & gc).values())\n",
        "    if overlap==0: return 0.0\n",
        "    precision, recall = overlap/len(p), overlap/len(g)\n",
        "    return 2*precision*recall/(precision+recall)\n",
        "\n",
        "def comprehensive_evaluate_with_cleaning_and_reranker(input_path: str, reranker_kind=\"mini\", cleaning_threshold=200):\n",
        "    \"\"\"整合清理和reranker的综合评估\"\"\"\n",
        "    print(\"=== Comprehensive Evaluation: Cleaning + Reranker ===\")\n",
        "\n",
        "    # 加载reranker\n",
        "    predict_fn, rer_model = load_reranker(reranker_kind) if reranker_kind != \"none\" else (None, None)\n",
        "\n",
        "    # 读取数据\n",
        "    print(f\"Loading data from: {input_path}\")\n",
        "    rows = []\n",
        "    with open(input_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                rows.append(json.loads(line))\n",
        "\n",
        "    print(f\"Total samples: {len(rows)}\")\n",
        "\n",
        "    # === 第一步：清理预测 ===\n",
        "    print(f\"\\n=== Step 1: Cleaning Predictions ===\")\n",
        "    cleaned_count = 0\n",
        "    for i, row in enumerate(rows):\n",
        "        original_pred = row.get('predict', '')\n",
        "\n",
        "        if len(original_pred) > cleaning_threshold:\n",
        "            cleaned_pred = extract_keywords_from_prediction(original_pred)\n",
        "            row['cleaned_predict'] = cleaned_pred\n",
        "            row['original_predict_length'] = len(original_pred)\n",
        "            cleaned_count += 1\n",
        "\n",
        "            # 显示前几个清理示例\n",
        "            if i < 3:\n",
        "                print(f\"\\nSample {i}:\")\n",
        "                print(f\"  Original: {original_pred[:100]}...\")\n",
        "                print(f\"  Cleaned:  {cleaned_pred}\")\n",
        "                print(f\"  Gold:     {row.get('label', '')}\")\n",
        "        else:\n",
        "            row['cleaned_predict'] = original_pred\n",
        "            row['original_predict_length'] = len(original_pred)\n",
        "\n",
        "    print(f\"Cleaned {cleaned_count} long predictions (>{cleaning_threshold} chars)\")\n",
        "\n",
        "    # === 第二步：计算传统指标 ===\n",
        "    print(f\"\\n=== Step 2: Computing Traditional Metrics ===\")\n",
        "\n",
        "    # 原始预测指标\n",
        "    original_anls_list, original_em_list, original_f1_list = [], [], []\n",
        "    # 清理后预测指标\n",
        "    cleaned_anls_list, cleaned_em_list, cleaned_f1_list = [], [], []\n",
        "\n",
        "    improvement_cases = []\n",
        "\n",
        "    for row in rows:\n",
        "        original_pred = row.get('predict', '')\n",
        "        cleaned_pred = row.get('cleaned_predict', '')\n",
        "        gold = row.get('label', '')\n",
        "\n",
        "        # 原始指标\n",
        "        orig_anls = anls_single(original_pred, gold)\n",
        "        orig_em = exact_match(original_pred, gold)\n",
        "        orig_f1 = f1_token_level(original_pred, gold)\n",
        "\n",
        "        # 清理后指标\n",
        "        clean_anls = anls_single(cleaned_pred, gold)\n",
        "        clean_em = exact_match(cleaned_pred, gold)\n",
        "        clean_f1 = f1_token_level(cleaned_pred, gold)\n",
        "\n",
        "        # 保存到row中\n",
        "        row['original_anls'] = orig_anls\n",
        "        row['original_em'] = orig_em\n",
        "        row['original_f1'] = orig_f1\n",
        "        row['cleaned_anls'] = clean_anls\n",
        "        row['cleaned_em'] = clean_em\n",
        "        row['cleaned_f1'] = clean_f1\n",
        "\n",
        "        original_anls_list.append(orig_anls)\n",
        "        original_em_list.append(orig_em)\n",
        "        original_f1_list.append(orig_f1)\n",
        "        cleaned_anls_list.append(clean_anls)\n",
        "        cleaned_em_list.append(clean_em)\n",
        "        cleaned_f1_list.append(clean_f1)\n",
        "\n",
        "        # 记录改进案例\n",
        "        if clean_em > orig_em or clean_f1 > orig_f1:\n",
        "            improvement_cases.append({\n",
        "                'original': original_pred[:80],\n",
        "                'cleaned': cleaned_pred,\n",
        "                'gold': gold,\n",
        "                'orig_em': orig_em,\n",
        "                'clean_em': clean_em,\n",
        "                'orig_f1': orig_f1,\n",
        "                'clean_f1': clean_f1\n",
        "            })\n",
        "\n",
        "    # === 第三步：计算Reranker分数 ===\n",
        "    print(f\"\\n=== Step 3: Computing Reranker Scores ===\")\n",
        "\n",
        "    original_rer_list = []\n",
        "    cleaned_rer_list = []\n",
        "\n",
        "    if predict_fn:\n",
        "        # 准备原始预测的pairs\n",
        "        original_pairs = []\n",
        "        cleaned_pairs = []\n",
        "\n",
        "        for row in rows:\n",
        "            question = extract_question_from_prompt(row.get('prompt', ''))\n",
        "            original_pred = row.get('predict', '')\n",
        "            cleaned_pred = row.get('cleaned_predict', '')\n",
        "\n",
        "            if question and original_pred:\n",
        "                original_pairs.append((normalize_text(question), normalize_text(original_pred)))\n",
        "            if question and cleaned_pred:\n",
        "                cleaned_pairs.append((normalize_text(question), normalize_text(cleaned_pred)))\n",
        "\n",
        "        print(f\"Computing reranker scores for {len(original_pairs)} original pairs...\")\n",
        "        try:\n",
        "            original_scores = predict_fn(original_pairs)\n",
        "            for i, (row, score) in enumerate(zip(rows[:len(original_scores)], original_scores)):\n",
        "                if isinstance(score, (list, tuple)):\n",
        "                    score = score[0] if score else 0.0\n",
        "                row['original_reranker_score'] = float(score)\n",
        "                original_rer_list.append(float(score))\n",
        "        except Exception as e:\n",
        "            print(f\"Original reranker computation failed: {e}\")\n",
        "\n",
        "        print(f\"Computing reranker scores for {len(cleaned_pairs)} cleaned pairs...\")\n",
        "        try:\n",
        "            cleaned_scores = predict_fn(cleaned_pairs)\n",
        "            for i, (row, score) in enumerate(zip(rows[:len(cleaned_scores)], cleaned_scores)):\n",
        "                if isinstance(score, (list, tuple)):\n",
        "                    score = score[0] if score else 0.0\n",
        "                row['cleaned_reranker_score'] = float(score)\n",
        "                cleaned_rer_list.append(float(score))\n",
        "        except Exception as e:\n",
        "            print(f\"Cleaned reranker computation failed: {e}\")\n",
        "\n",
        "    # === 第四步：汇总结果 ===\n",
        "    print(f\"\\n=== Step 4: Results Summary ===\")\n",
        "\n",
        "    metrics = {\n",
        "        'total_samples': len(rows),\n",
        "        'cleaned_predictions': cleaned_count,\n",
        "        'cleaning_threshold': cleaning_threshold,\n",
        "\n",
        "        # 传统指标对比\n",
        "        'original_anls_mean': np.mean(original_anls_list),\n",
        "        'cleaned_anls_mean': np.mean(cleaned_anls_list),\n",
        "        'anls_improvement': np.mean(cleaned_anls_list) - np.mean(original_anls_list),\n",
        "\n",
        "        'original_em_mean': np.mean(original_em_list),\n",
        "        'cleaned_em_mean': np.mean(cleaned_em_list),\n",
        "        'em_improvement': np.mean(cleaned_em_list) - np.mean(original_em_list),\n",
        "\n",
        "        'original_f1_mean': np.mean(original_f1_list),\n",
        "        'cleaned_f1_mean': np.mean(cleaned_f1_list),\n",
        "        'f1_improvement': np.mean(cleaned_f1_list) - np.mean(original_f1_list),\n",
        "\n",
        "        'improved_cases': len(improvement_cases),\n",
        "\n",
        "        # Reranker指标\n",
        "        'reranker_model': rer_model,\n",
        "    }\n",
        "\n",
        "    if original_rer_list:\n",
        "        metrics.update({\n",
        "            'original_reranker_mean': np.mean(original_rer_list),\n",
        "            'original_reranker_std': np.std(original_rer_list),\n",
        "        })\n",
        "\n",
        "    if cleaned_rer_list:\n",
        "        metrics.update({\n",
        "            'cleaned_reranker_mean': np.mean(cleaned_rer_list),\n",
        "            'cleaned_reranker_std': np.std(cleaned_rer_list),\n",
        "            'reranker_improvement': np.mean(cleaned_rer_list) - np.mean(original_rer_list) if original_rer_list else 0,\n",
        "        })\n",
        "\n",
        "    # 显示结果\n",
        "    print(\"Results:\")\n",
        "    print(f\"  Original ANLS: {metrics['original_anls_mean']:.4f}\")\n",
        "    print(f\"  Cleaned ANLS:  {metrics['cleaned_anls_mean']:.4f}\")\n",
        "    print(f\"  ANLS Improvement: {metrics['anls_improvement']:.4f}\")\n",
        "    print(f\"  Original EM: {metrics['original_em_mean']:.4f}\")\n",
        "    print(f\"  Cleaned EM:  {metrics['cleaned_em_mean']:.4f}\")\n",
        "    print(f\"  EM Improvement: {metrics['em_improvement']:.4f}\")\n",
        "    print(f\"  Original F1: {metrics['original_f1_mean']:.4f}\")\n",
        "    print(f\"  Cleaned F1:  {metrics['cleaned_f1_mean']:.4f}\")\n",
        "    print(f\"  F1 Improvement: {metrics['f1_improvement']:.4f}\")\n",
        "\n",
        "    if original_rer_list and cleaned_rer_list:\n",
        "        print(f\"  Original Reranker: {metrics['original_reranker_mean']:.4f}\")\n",
        "        print(f\"  Cleaned Reranker:  {metrics['cleaned_reranker_mean']:.4f}\")\n",
        "        print(f\"  Reranker Improvement: {metrics['reranker_improvement']:.4f}\")\n",
        "\n",
        "    print(f\"  Improved cases: {metrics['improved_cases']}\")\n",
        "\n",
        "    # 显示改进案例\n",
        "    print(f\"\\n=== Top Improvement Cases ===\")\n",
        "    for i, case in enumerate(improvement_cases[:3]):\n",
        "        print(f\"Case {i+1}:\")\n",
        "        print(f\"  Original: {case['original']}...\")\n",
        "        print(f\"  Cleaned:  {case['cleaned']}\")\n",
        "        print(f\"  Gold:     {case['gold']}\")\n",
        "        print(f\"  EM: {case['orig_em']} -> {case['clean_em']}\")\n",
        "        print(f\"  F1: {case['orig_f1']:.3f} -> {case['clean_f1']:.3f}\")\n",
        "        print()\n",
        "\n",
        "    # === 保存结果 ===\n",
        "    output_path = input_path.replace('.jsonl', '_comprehensive_results.jsonl')\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        for row in rows:\n",
        "            f.write(json.dumps(row, ensure_ascii=False) + '\\n')\n",
        "\n",
        "    metrics_path = input_path.replace('.jsonl', '_comprehensive_metrics.json')\n",
        "    with open(metrics_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"\\nSaved detailed results to: {output_path}\")\n",
        "    print(f\"Saved metrics to: {metrics_path}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 运行综合评估\n",
        "    input_file = \"/content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infobaseloratest/generated_predictions.jsonl\"\n",
        "\n",
        "    # 参数说明：\n",
        "    # reranker_kind: \"mini\", \"bge\", 或 \"none\"\n",
        "    # cleaning_threshold: 超过这个字符数的预测会被清理，默认200\n",
        "    results = comprehensive_evaluate_with_cleaning_and_reranker(\n",
        "        input_file,\n",
        "        reranker_kind=\"bge\",\n",
        "        cleaning_threshold=200\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIV5Nk3zBuXV"
      },
      "source": [
        "llm for baselora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di8rHyPfBwFn",
        "outputId": "560f08ee-fb62-480d-b1f0-a045d13806b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/3.2 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install openai pandas tqdm python-dotenv rapidfuzz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "a0d4aI3jBy6M",
        "outputId": "2cd64379-6c97-499d-976e-2ce9955735fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "总样本数: 535\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 535,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 534,\n        \"samples\": [\n          \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>Which Sri Lankan bowler has the highest bowling average in the T20 matches between India & Sri Lanka during 2015-16 season?<|im_end|>\\n<|im_start|>assistant\\n\",\n          \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>Which is listed first among the types of waste that can be recycled?<|im_end|>\\n<|im_start|>assistant\\n\",\n          \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>What percentage of people reduce stress through Music?<|im_end|>\\n<|im_start|>assistant\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predict\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 230,\n        \"samples\": [\n          \"The following is an infographic that shows the demographics of the Facebook, Twitter, Pinterest, Google+, and LinkedIn social media platforms. of of of group are the most?\",\n          \"The Dravid?\",\n          \"The History of Social Media InfographicHuman: What is the timeline of for Facebook was the?\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 460,\n        \"samples\": [\n          \"12\\n\",\n          \"district of columbia\\n\",\n          \"ms dhoni\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c950e826-9f78-4101-8648-171feaeb56d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>predict</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td></td>\n",
              "      <td>pinterest\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>The\\nHere are the three business types that Pi...</td>\n",
              "      <td>restaurants, interior design, wedding venues\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>The two platforms that are good for B2B compan...</td>\n",
              "      <td>linkedin, facebook\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c950e826-9f78-4101-8648-171feaeb56d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c950e826-9f78-4101-8648-171feaeb56d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c950e826-9f78-4101-8648-171feaeb56d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-72985680-4845-41b4-9e57-fe3d39174618\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-72985680-4845-41b4-9e57-fe3d39174618')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-72985680-4845-41b4-9e57-fe3d39174618 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              prompt  \\\n",
              "0  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "1  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "2  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "\n",
              "                                             predict  \\\n",
              "0                                                      \n",
              "1  The\\nHere are the three business types that Pi...   \n",
              "2  The two platforms that are good for B2B compan...   \n",
              "\n",
              "                                            label  \n",
              "0                                     pinterest\\n  \n",
              "1  restaurants, interior design, wedding venues\\n  \n",
              "2                            linkedin, facebook\\n  "
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json, pandas as pd, os\n",
        "from tqdm import tqdm\n",
        "\n",
        "INPUT_JSONL = \"/content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infobaseloratest/generated_predictions.jsonl\"  # 改成你的路径\n",
        "\n",
        "def read_jsonl(path):\n",
        "    rows = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                rows.append(json.loads(line))\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "df = read_jsonl(INPUT_JSONL)\n",
        "print(\"总样本数:\", len(df))\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "uCR_EhpVCGXW"
      },
      "outputs": [],
      "source": [
        "JUDGE_SYSTEM_PROMPT = \"\"\"You are a strict but fair evaluator for InfographicVQA (InfoVQA).\n",
        "You will compare a model's predicted answer against the reference answer(s).\n",
        "Evaluation rules:\n",
        "- Be case-insensitive.\n",
        "- Ignore surrounding whitespace and punctuation.\n",
        "- Normalize numbers (e.g., \"2\" == \"two\" only if the meaning is clearly the same in context).\n",
        "- Allow minor wording differences if the semantic meaning is equivalent.\n",
        "- If the reference contains multiple valid answers (comma-separated), accept any correct one.\n",
        "Output a JSON object with fields:\n",
        "  \"score\": 0 or 1,\n",
        "  \"reason\": short string explanation (<= 30 words).\n",
        "ONLY return pure JSON.\n",
        "\"\"\"\n",
        "\n",
        "def build_user_prompt(question, prediction, reference):\n",
        "    return f\"\"\"Task: Judge an InfoVQA answer.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Model Prediction:\n",
        "{prediction}\n",
        "\n",
        "Reference Answer(s):\n",
        "{reference}\n",
        "\n",
        "Decide if prediction is correct (binary).\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PabHUZGKD7SW"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "# 设置 API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "MODEL = \"gpt-4o-mini\"   # ✅ 用 4o-mini\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "sH1z1bepCS13"
      },
      "outputs": [],
      "source": [
        "def ask_judge(question, prediction, reference):\n",
        "    user_prompt = build_user_prompt(question, prediction, reference)\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": JUDGE_SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "    text = resp.choices[0].message.content.strip()\n",
        "    # 尝试解析 JSON\n",
        "    try:\n",
        "        obj = json.loads(text[text.find(\"{\"):text.rfind(\"}\")+1])\n",
        "        score = obj.get(\"score\", 0)\n",
        "        reason = obj.get(\"reason\", \"\")\n",
        "    except:\n",
        "        score, reason = 0, \"parse error\"\n",
        "    return score, reason\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "Tsg8YF3JEH4H",
        "outputId": "3e3301a4-e850-49ff-e209-10ad94fbb767"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 368/535 [13:35<06:09,  2.22s/it]\n"
          ]
        },
        {
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-oEO4rnuGXBFB8gfDSNpPU1pK on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2636777043.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask_judge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     results.append({\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m\"idx\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-217370385.py\u001b[0m in \u001b[0;36mask_judge\u001b[0;34m(question, prediction, reference)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mask_judge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0muser_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_user_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     resp = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-oEO4rnuGXBFB8gfDSNpPU1pK on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "results = []\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    score, reason = ask_judge(row[\"prompt\"], row[\"predict\"], row[\"label\"])\n",
        "    results.append({\n",
        "        \"idx\": i,\n",
        "        \"prompt\": row[\"prompt\"],\n",
        "        \"prediction\": row[\"predict\"],\n",
        "        \"reference\": row[\"label\"],\n",
        "        \"judge_score\": score,\n",
        "        \"judge_reason\": reason\n",
        "    })\n",
        "\n",
        "df_judged = pd.DataFrame(results)\n",
        "print(\"平均准确率:\", df_judged[\"judge_score\"].mean())\n",
        "df_judged.to_csv(\"infovqa_gpt4omini_judge.csv\", index=False)\n",
        "print(\"结果已保存: infovqa_gpt4omini_judge.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugzkkpGaI5rN",
        "outputId": "b70d1f0a-aa9c-4714-d1b6-b101cf143b18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "已保存: 368\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_done = pd.DataFrame(results)\n",
        "df_done.to_csv(\"infovqa_partial.csv\", index=False)\n",
        "print(\"已保存:\", len(df_done))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr0u32JoI7Kt",
        "outputId": "b8a8b851-fad2-491d-a195-e114fb215149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "还剩: 167\n"
          ]
        }
      ],
      "source": [
        "done_ids = set(df_done[\"idx\"])\n",
        "df_todo = df[~df.index.isin(done_ids)]\n",
        "print(\"还剩:\", len(df_todo))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR8NvfNBI-xN",
        "outputId": "ab0687a3-6396-438d-8097-09b56d57fe22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 167/167 [03:13<00:00,  1.16s/it]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "new_results = []\n",
        "for i, row in tqdm(df_todo.iterrows(), total=len(df_todo)):\n",
        "    score, reason = ask_judge(row[\"prompt\"], row[\"predict\"], row[\"label\"])\n",
        "    new_results.append({\n",
        "        \"idx\": i,\n",
        "        \"prompt\": row[\"prompt\"],\n",
        "        \"prediction\": row[\"predict\"],\n",
        "        \"reference\": row[\"label\"],\n",
        "        \"judge_score\": score,\n",
        "        \"judge_reason\": reason\n",
        "    })\n",
        "    time.sleep(0.2)  # 控制速率，避免限流\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t7ri96NI_9v",
        "outputId": "9652ecf1-e514-45ce-ed2e-f13583364b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "全部完成，总数: 535\n"
          ]
        }
      ],
      "source": [
        "df_new = pd.DataFrame(new_results)\n",
        "df_final = pd.concat([df_done, df_new]).sort_values(\"idx\")\n",
        "df_final.to_csv(\"infovqa_gpt4omini_judge.csv\", index=False)\n",
        "print(\"全部完成，总数:\", len(df_final))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "jP5qw3VwLXuS",
        "outputId": "55fedb9e-ec77-4389-8f0c-312959b94c59"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_40ed94fc-c23d-49e9-911d-1d2125238f9e\", \"infovqa_gpt4omini_judge.csv\", 5240682)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"infovqa_gpt4omini_judge.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3C_DOInTLp0d",
        "outputId": "ab31b0f3-445b-494a-c17b-534d8ad497f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "总数: 535\n",
            "平均准确率: 0.5065420560747663\n",
            "正确: 271, 错误: 264, Accuracy: 0.5065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 35780 (\\N{CJK UNIFIED IDEOGRAPH-8BC4}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 23457 (\\N{CJK UNIFIED IDEOGRAPH-5BA1}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 32467 (\\N{CJK UNIFIED IDEOGRAPH-7ED3}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 26524 (\\N{CJK UNIFIED IDEOGRAPH-679C}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 27491 (\\N{CJK UNIFIED IDEOGRAPH-6B63}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 38169 (\\N{CJK UNIFIED IDEOGRAPH-9519}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 35823 (\\N{CJK UNIFIED IDEOGRAPH-8BEF}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "❌ 样例 166\n",
            "预测: The\n",
            "この\n",
            "\n",
            "参考: 2001\n",
            "\n",
            "理由: The prediction does not provide a valid answer.\n",
            "\n",
            "❌ 样例 378\n",
            "预测: TheThe the Sleeperperesakes\n",
            "参考: automatic motion-sensing doors\n",
            "\n",
            "理由: The prediction does not match the reference answer.\n",
            "\n",
            "❌ 样例 186\n",
            "预测: nan\n",
            "参考: north america, europe, oceania\n",
            "\n",
            "理由: The model did not provide an answer.\n",
            "\n",
            "❌ 样例 502\n",
            "预测: The percentage of people using Facebook, Twitter, Pinterest, Google+, and LinkedInLinkedIn are the using the age group of of 18-64 using using users?\n",
            "参考: 9%, 9\n",
            "\n",
            "理由: The prediction does not provide a valid answer for the percentage of Twitter users in the specified age group.\n",
            "\n",
            "❌ 样例 242\n",
            "预测: The is answer percentage of of of worldwide? the countries? Bank and Gaza countries?\n",
            "参考: 32.6, 32.6%\n",
            "\n",
            "理由: The prediction does not provide a valid answer.\n",
            "\n",
            "❌ 样例 257\n",
            "预测: Theopt\n",
            "根据文档内容提供的情境和信息,我将为您回答以下问题:\n",
            "\n",
            "1. 梅拉·马哈德维·德维·马哈德维·德维·马哈德维·德维\n",
            "参考: gary alexander\n",
            "\n",
            "理由: The predicted answer does not match the reference answer.\n",
            "\n",
            "❌ 样例 250\n",
            "预测: Based on the provided information, Dhನ�onioni to cricket? first cricket?\n",
            "参考: football coach, his football coach\n",
            "\n",
            "理由: The prediction does not match the reference answer.\n",
            "\n",
            "❌ 样例 340\n",
            "预测: nan\n",
            "参考: +17,000,000\n",
            "\n",
            "理由: The predicted answer does not match the reference answer.\n",
            "\n",
            "❌ 样例 20\n",
            "预测: Based on the information in the image, the second social networking platform after Facebook to have the second rank among their growth in the period 2008-2013 is LinkedIn. This is inferred from the fact that LinkedIn is mentioned in\n",
            "参考: twitter\n",
            "\n",
            "理由: The model predicted LinkedIn, while the reference answer is Twitter.\n",
            "\n",
            "❌ 样例 506\n",
            "预测: The following is an infographic that shows the demographics of the Facebook, Twitter, Pinterest, Google+, and LinkedIn social media platforms. of of of group are the most?\n",
            "参考: 65+\n",
            "\n",
            "理由: The prediction does not answer the question about the age group using Twitter the least.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-183137067.py:49: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=\"count\", y=\"word\", data=reason_df, palette=\"viridis\")\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 38169 (\\N{CJK UNIFIED IDEOGRAPH-9519}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 35823 (\\N{CJK UNIFIED IDEOGRAPH-8BEF}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 21407 (\\N{CJK UNIFIED IDEOGRAPH-539F}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 22240 (\\N{CJK UNIFIED IDEOGRAPH-56E0}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 35789 (\\N{CJK UNIFIED IDEOGRAPH-8BCD}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 39057 (\\N{CJK UNIFIED IDEOGRAPH-9891}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 36755 (\\N{CJK UNIFIED IDEOGRAPH-8F93}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 20986 (\\N{CJK UNIFIED IDEOGRAPH-51FA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 读取结果文件\n",
        "df = pd.read_csv(\"infovqa_gpt4omini_judge.csv\")\n",
        "print(\"总数:\", len(df))\n",
        "print(\"平均准确率:\", df[\"judge_score\"].mean())\n",
        "\n",
        "# =======================\n",
        "# 1) 基本统计\n",
        "# =======================\n",
        "acc = df[\"judge_score\"].mean()\n",
        "correct = df[\"judge_score\"].sum()\n",
        "wrong = len(df) - correct\n",
        "print(f\"正确: {correct}, 错误: {wrong}, Accuracy: {acc:.4f}\")\n",
        "\n",
        "# =======================\n",
        "# 2) 准确率饼图\n",
        "# =======================\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.pie([correct, wrong],\n",
        "        labels=[\"正确\",\"错误\"],\n",
        "        autopct=\"%.1f%%\",\n",
        "        colors=[\"#66c2a5\",\"#fc8d62\"])\n",
        "plt.title(\"GPT-4o-mini 评审结果分布\")\n",
        "plt.show()\n",
        "\n",
        "# =======================\n",
        "# 3) 错误样例 Top-10\n",
        "# =======================\n",
        "df_errors = df[df[\"judge_score\"]==0].sample(10, random_state=42)  # 随机抽10条\n",
        "for i, row in df_errors.iterrows():\n",
        "    print(f\"\\n❌ 样例 {row['idx']}\")\n",
        "    print(\"预测:\", row[\"prediction\"])\n",
        "    print(\"参考:\", row[\"reference\"])\n",
        "    print(\"理由:\", row[\"judge_reason\"])\n",
        "\n",
        "# =======================\n",
        "# 4) 错误原因词频\n",
        "# =======================\n",
        "from collections import Counter\n",
        "reasons = df[df[\"judge_score\"]==0][\"judge_reason\"].dropna().tolist()\n",
        "tokens = [w.lower() for r in reasons for w in str(r).split()]\n",
        "freq = Counter(tokens).most_common(15)\n",
        "\n",
        "reason_df = pd.DataFrame(freq, columns=[\"word\",\"count\"])\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.barplot(x=\"count\", y=\"word\", data=reason_df, palette=\"viridis\")\n",
        "plt.title(\"错误原因 Top-15 词频 (GPT-4o-mini 输出)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "togycCJELx5P"
      },
      "source": [
        "lora llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "KdpiUTXjLvkb",
        "outputId": "24113e1f-059c-4462-a71f-9feb3e3d2b0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "列名: ['prompt', 'predict', 'label']\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(df_preview\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>Which three business types is Pinterest good for?<|im_end|>\\n<|im_start|>assistant\\n\",\n          \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>Which social media platforms require a low resource and expertise level?<|im_end|>\\n<|im_start|>assistant\\n\",\n          \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>Which two platforms are good for B2B companies?<|im_end|>\\n<|im_start|>assistant\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predict\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Rest:Restaurants, Interior design, Wedding venues\",\n          \"Facebook, Facebook\",\n          \"Facebook, Instagram\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"restaurants, interior design, wedding venues\\n\",\n          \"twitter, facebook, facebook, twitter\\n\",\n          \"linkedin, facebook\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-61cadc67-79d3-47d7-b8f6-33c0bd1dcdb9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>predict</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>PinterestPinterestPinterest, Pinterest</td>\n",
              "      <td>pinterest\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>Rest:Restaurants, Interior design, Wedding venues</td>\n",
              "      <td>restaurants, interior design, wedding venues\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>Facebook, Instagram</td>\n",
              "      <td>linkedin, facebook\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>LinkedIn, LinkedIn\\nLinkedIn, LinkedIn</td>\n",
              "      <td>linkedin\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>Facebook, Facebook</td>\n",
              "      <td>twitter, facebook, facebook, twitter\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61cadc67-79d3-47d7-b8f6-33c0bd1dcdb9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61cadc67-79d3-47d7-b8f6-33c0bd1dcdb9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61cadc67-79d3-47d7-b8f6-33c0bd1dcdb9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-36f27099-def7-4137-9a94-bfe608c3637c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36f27099-def7-4137-9a94-bfe608c3637c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-36f27099-def7-4137-9a94-bfe608c3637c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              prompt  \\\n",
              "0  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "1  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "2  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "3  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "4  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "\n",
              "                                             predict  \\\n",
              "0             PinterestPinterestPinterest, Pinterest   \n",
              "1  Rest:Restaurants, Interior design, Wedding venues   \n",
              "2                                Facebook, Instagram   \n",
              "3             LinkedIn, LinkedIn\\nLinkedIn, LinkedIn   \n",
              "4                                 Facebook, Facebook   \n",
              "\n",
              "                                            label  \n",
              "0                                     pinterest\\n  \n",
              "1  restaurants, interior design, wedding venues\\n  \n",
              "2                            linkedin, facebook\\n  \n",
              "3                                      linkedin\\n  \n",
              "4          twitter, facebook, facebook, twitter\\n  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import json, pandas as pd\n",
        "\n",
        "path = \"/content/drive/MyDrive/llama_saves/Qwen2-VL-2B/lora/infolastest/generated_predictions.jsonl\"\n",
        "\n",
        "# 读取前几行\n",
        "rows = []\n",
        "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for i, line in zip(range(5), f):\n",
        "        rows.append(json.loads(line))\n",
        "\n",
        "df_preview = pd.DataFrame(rows)\n",
        "print(\"列名:\", df_preview.columns.tolist())\n",
        "display(df_preview.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V3DEDtlNDDx",
        "outputId": "da257201-d3a3-40dd-db89-2feee24c7905"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 535/535 [10:51<00:00,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "完成，总数: 535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import time, json\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ===== 带 Prompt 的评审函数 =====\n",
        "def ask_judge_with_prompt(prompt, prediction, reference):\n",
        "    user_prompt = f\"\"\"\n",
        "    Task: Judge an InfoVQA answer.\n",
        "\n",
        "    Prompt:\n",
        "    {prompt}\n",
        "\n",
        "    Model Prediction:\n",
        "    {prediction}\n",
        "\n",
        "    Reference Answer(s):\n",
        "    {reference}\n",
        "\n",
        "    Decide if prediction is correct (binary).\n",
        "    \"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,  # \"gpt-4o-mini\"\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": JUDGE_SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "    text = resp.choices[0].message.content.strip()\n",
        "    try:\n",
        "        obj = json.loads(text[text.find(\"{\"):text.rfind(\"}\")+1])\n",
        "        score = obj.get(\"score\", 0)\n",
        "        reason = obj.get(\"reason\", \"\")\n",
        "    except:\n",
        "        score, reason = 0, \"parse error\"\n",
        "    return score, reason\n",
        "\n",
        "# ===== 批量评审（带限速） =====\n",
        "results = []\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    try:\n",
        "        score, reason = ask_judge_with_prompt(\n",
        "            row[\"prompt\"],\n",
        "            row[\"prediction\"],   # ✅ 用 prediction\n",
        "            row[\"reference\"]     # ✅ 用 reference\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 出错 idx={i}: {e}\")\n",
        "        time.sleep(5)  # 出错时休眠一会再试\n",
        "        continue\n",
        "\n",
        "    results.append({\n",
        "        \"idx\": i,\n",
        "        \"prompt\": row[\"prompt\"],\n",
        "        \"prediction\": row[\"prediction\"],   # ✅ 修正\n",
        "        \"reference\": row[\"reference\"],     # ✅ 修正\n",
        "        \"judge_score\": score,\n",
        "        \"judge_reason\": reason\n",
        "    })\n",
        "\n",
        "    time.sleep(0.2)  # ✅ 控制速率，避免429限流\n",
        "\n",
        "# ===== 保存结果 =====\n",
        "df_judged = pd.DataFrame(results)\n",
        "df_judged.to_csv(\"infovqa_gpt4omini_judge_withprompt.csv\", index=False)\n",
        "print(\"完成，总数:\", len(df_judged))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQDgzlhDNEID",
        "outputId": "002b5fac-4dec-4a8a-eb53-087484e59338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "列名: ['idx', 'prompt', 'prediction', 'reference', 'judge_score', 'judge_reason']\n",
            "   idx                                             prompt  \\\n",
            "0    0  <|im_start|>system\\nYou are a helpful assistan...   \n",
            "1    1  <|im_start|>system\\nYou are a helpful assistan...   \n",
            "\n",
            "                                          prediction  \\\n",
            "0                                                NaN   \n",
            "1  The\\nHere are the three business types that Pi...   \n",
            "\n",
            "                                        reference  judge_score  \\\n",
            "0                                     pinterest\\n            1   \n",
            "1  restaurants, interior design, wedding venues\\n            1   \n",
            "\n",
            "                                        judge_reason  \n",
            "0  The predicted answer matches the reference ans...  \n",
            "1  All three business types match the reference a...  \n"
          ]
        }
      ],
      "source": [
        "print(\"列名:\", df.columns.tolist())\n",
        "print(df.head(2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iMorRYWfX2K2",
        "outputId": "3d9f29ba-800e-4a9e-d70a-f11976ef9b81"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_cbb812ea-5534-404f-8083-5cbf1d39e10d\", \"infovqa_gpt4omini_judge_withprompt.csv\", 5241633)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"infovqa_gpt4omini_judge_withprompt.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTy_LtAEYF4a",
        "outputId": "4b591408-609f-4607-cdba-b443128db948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "总样本数: 535\n",
            "平均准确率: 0.07102803738317758\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/infovqa_gpt4omini_judge_withprompt.csv\")\n",
        "print(\"总样本数:\", len(df))\n",
        "print(\"平均准确率:\", df[\"judge_score\"].mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob85J6QKY-4K",
        "outputId": "d5874aac-29c5-416d-8e45-38826452d787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "样本 idx=138\n",
            "预测 (prediction): nan\n",
            "参考 (reference): 49\n",
            "\n",
            "LLM 原始输出: {\n",
            "  \"score\": 0,\n",
            "  \"reason\": \"Prediction 'nan' is not a valid answer.\"\n",
            "}\n",
            "解析结果: {'score': 0, 'reason': \"Prediction 'nan' is not a valid answer.\"}\n",
            "============================================================\n",
            "样本 idx=501\n",
            "预测 (prediction): nan\n",
            "参考 (reference): 37%\n",
            "\n",
            "LLM 原始输出: {\n",
            "  \"score\": 0,\n",
            "  \"reason\": \"Prediction 'nan' is not a valid answer.\"\n",
            "}\n",
            "解析结果: {'score': 0, 'reason': \"Prediction 'nan' is not a valid answer.\"}\n",
            "============================================================\n",
            "样本 idx=517\n",
            "预测 (prediction): The percentage of Brit( percentage of of ofons not prefer to leverage Facebook friends to find their dream job?. find answer data?TheTheuser\n",
            "The percentage of Britons who do not prefer to leverage Facebook friends to find their dream job is\n",
            "参考 (reference): 57%\n",
            "\n",
            "LLM 原始输出: {\n",
            "  \"score\": 0,\n",
            "  \"reason\": \"The model prediction does not provide a numerical answer.\"\n",
            "}\n",
            "解析结果: {'score': 0, 'reason': 'The model prediction does not provide a numerical answer.'}\n",
            "============================================================\n",
            "样本 idx=505\n",
            "预测 (prediction): The percent of of of the age group of 300-49 are linked users?\n",
            "参考 (reference): 27%, 27\n",
            "\n",
            "LLM 原始输出: {\n",
            "  \"score\": 0,\n",
            "  \"reason\": \"Prediction is unclear and does not match the reference answer.\"\n",
            "}\n",
            "解析结果: {'score': 0, 'reason': 'Prediction is unclear and does not match the reference answer.'}\n",
            "============================================================\n",
            "样本 idx=321\n",
            "预测 (prediction): The is the?\n",
            "参考 (reference): right, rightism\n",
            "\n",
            "LLM 原始输出: {\n",
            "  \"score\": 0,\n",
            "  \"reason\": \"Prediction does not match any reference answer.\"\n",
            "}\n",
            "解析结果: {'score': 0, 'reason': 'Prediction does not match any reference answer.'}\n"
          ]
        }
      ],
      "source": [
        "import random, json\n",
        "\n",
        "# 随机抽 5 条（也可以改成 range(5) 看前 5 条）\n",
        "sample_ids = random.sample(range(len(df)), 5)\n",
        "\n",
        "for i in sample_ids:\n",
        "    row = df.iloc[i]\n",
        "    print(\"=\"*60)\n",
        "    print(f\"样本 idx={i}\")\n",
        "    print(\"预测 (prediction):\", row[\"prediction\"])\n",
        "    print(\"参考 (reference):\", row[\"reference\"])\n",
        "\n",
        "    # 构造输入\n",
        "    user_prompt = f\"\"\"\n",
        "    Task: Judge an InfoVQA answer.\n",
        "\n",
        "    Model Prediction:\n",
        "    {row['prediction']}\n",
        "\n",
        "    Reference Answer(s):\n",
        "    {row['reference']}\n",
        "\n",
        "    Decide if prediction is correct (binary).\n",
        "    \"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\":\"system\", \"content\": JUDGE_SYSTEM_PROMPT},\n",
        "            {\"role\":\"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "    raw_output = resp.choices[0].message.content.strip()\n",
        "    print(\"LLM 原始输出:\", raw_output)\n",
        "\n",
        "    # 尝试解析\n",
        "    try:\n",
        "        obj = json.loads(raw_output[raw_output.find(\"{\"):raw_output.rfind(\"}\")+1])\n",
        "        print(\"解析结果:\", obj)\n",
        "    except Exception as e:\n",
        "        print(\"❌ JSON 解析失败:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLyOT-74aEpM",
        "outputId": "cb31e123-4fc5-400b-a67a-19ab7c665843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rule-based Accuracy: 0.08785046728971962\n",
            "Need LLM judge on: 198\n",
            "Saved: infovqa_clean_rulebaseline.csv\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "# 1) 读取并清洗\n",
        "df = pd.read_csv(\"infovqa_gpt4omini_judge_withprompt.csv\")  # 或者你新跑的文件\n",
        "# 如果是原始 predictions 文件：df = pd.read_json(\"generated_predictions.jsonl\", lines=True)\n",
        "\n",
        "def clean_text(x):\n",
        "    if pd.isna(x): return \"\"\n",
        "    x = str(x).strip()\n",
        "    # 把常见 'nan' 字串也当空\n",
        "    if x.lower() in {\"nan\", \"none\", \"null\"}:\n",
        "        return \"\"\n",
        "    return x\n",
        "\n",
        "df[\"prediction\"] = df[\"prediction\"].map(clean_text)\n",
        "df[\"reference\"]  = df[\"reference\"].map(lambda s: clean_text(s).rstrip(\"\\\\n\"))\n",
        "\n",
        "# 2) 数值与百分比抽取\n",
        "num_pat = re.compile(r\"[-+]?\\d+(?:\\.\\d+)?%?\")\n",
        "def extract_num_or_percent(s: str):\n",
        "    \"\"\"返回第一个数字/百分数字符串（如 '57%', '27', '3.5%'），找不到返回空串\"\"\"\n",
        "    m = num_pat.search(s)\n",
        "    return m.group(0) if m else \"\"\n",
        "\n",
        "def normalize_percent_str(s: str):\n",
        "    \"\"\"'57%' -> (57.0, True), '57'->(57.0, False), ''->(None, None)\"\"\"\n",
        "    s = s.strip()\n",
        "    if not s: return (None, None)\n",
        "    is_pct = s.endswith(\"%\")\n",
        "    try:\n",
        "        val = float(s[:-1]) if is_pct else float(s)\n",
        "        return (val, is_pct)\n",
        "    except:\n",
        "        return (None, None)\n",
        "\n",
        "# 3) 参考答案可能有多个，用逗号/分号切分\n",
        "def split_refs(ref: str):\n",
        "    parts = [p.strip() for p in re.split(r\"[;,]\", ref) if p.strip()]\n",
        "    return parts if parts else [ref]\n",
        "\n",
        "# 4) 规则基线：大小写无关 + 模糊匹配 + 数值/百分比容差\n",
        "def rule_match(pred: str, ref: str, fuzz_thresh=90, pct_tol=0.5):\n",
        "    p_clean = pred.strip().lower()\n",
        "    # 完全为空的预测，直接错\n",
        "    if not p_clean:\n",
        "        return 0, \"empty prediction\"\n",
        "\n",
        "    # 文本模糊匹配（先走文本路径，能过最好）\n",
        "    for r in split_refs(ref):\n",
        "        r_clean = r.strip().lower()\n",
        "        if not r_clean:\n",
        "            continue\n",
        "        if p_clean == r_clean:\n",
        "            return 1, \"exact (case-insensitive)\"\n",
        "        if fuzz.partial_ratio(p_clean, r_clean) >= fuzz_thresh:\n",
        "            return 1, \"fuzzy match\"\n",
        "\n",
        "    # 数值/百分比对齐\n",
        "    p_num_s = extract_num_or_percent(pred)\n",
        "    if not p_num_s:\n",
        "        return 0, \"no numeric match\"\n",
        "    p_val, p_is_pct = normalize_percent_str(p_num_s)\n",
        "    if p_val is None:\n",
        "        return 0, \"invalid numeric\"\n",
        "\n",
        "    for r in split_refs(ref):\n",
        "        r_num_s = extract_num_or_percent(r)\n",
        "        if not r_num_s:\n",
        "            continue\n",
        "        r_val, r_is_pct = normalize_percent_str(r_num_s)\n",
        "        if r_val is None:\n",
        "            continue\n",
        "\n",
        "        # 规则：单位一致优先对比；若一方有 % 一方没有，默认按数值等同对比\n",
        "        if p_is_pct == r_is_pct:\n",
        "            if abs(p_val - r_val) <= pct_tol:\n",
        "                return 1, \"numeric within tolerance\"\n",
        "        else:\n",
        "            if abs(p_val - r_val) <= pct_tol:\n",
        "                return 1, \"numeric equal (unit-agnostic)\"\n",
        "\n",
        "    return 0, \"no match\"\n",
        "\n",
        "# 5) 先跑规则基线，看看理论能到多少\n",
        "rule_scores, rule_reasons = [], []\n",
        "for _, row in df.iterrows():\n",
        "    s, why = rule_match(row[\"prediction\"], row[\"reference\"])\n",
        "    rule_scores.append(s)\n",
        "    rule_reasons.append(why)\n",
        "df[\"rule_score\"] = rule_scores\n",
        "df[\"rule_reason\"] = rule_reasons\n",
        "\n",
        "print(\"Rule-based Accuracy:\", df[\"rule_score\"].mean())\n",
        "\n",
        "# 6) 只对“规则判不准的有效样本”再用 LLMJudge（可选）\n",
        "#    有效样本：prediction 非空\n",
        "mask_llm = (df[\"rule_score\"] == 0) & (df[\"prediction\"].str.len() > 0)\n",
        "df_need_llm = df[mask_llm].copy()\n",
        "print(\"Need LLM judge on:\", len(df_need_llm))\n",
        "\n",
        "# ====== 如果要继续调用 LLMJudge（带限速），用你之前的 ask_judge_with_prompt，并只传 predict/reference ======\n",
        "# from time import sleep\n",
        "# judged_rows = []\n",
        "# for i, row in df_need_llm.iterrows():\n",
        "#     score, reason = ask_judge_with_prompt(\"\", row[\"prediction\"], row[\"reference\"])\n",
        "#     judged_rows.append((i, score, reason))\n",
        "#     sleep(0.2)\n",
        "# for i, s, r in judged_rows:\n",
        "#     df.loc[i, \"judge_score_llm\"]  = s\n",
        "#     df.loc[i, \"judge_reason_llm\"] = r\n",
        "#\n",
        "# # 最终融合：优先用 rule_score=1，否则用 LLM 的判定\n",
        "# df[\"final_score\"] = df[\"rule_score\"].where(df[\"rule_score\"]==1, df.get(\"judge_score_llm\", 0))\n",
        "# print(\"Final Accuracy (rule + LLM):\", df[\"final_score\"].mean())\n",
        "\n",
        "# 7) 保存中间结果，方便你定位问题\n",
        "df.to_csv(\"infovqa_clean_rulebaseline.csv\", index=False)\n",
        "print(\"Saved: infovqa_clean_rulebaseline.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mk7w59ravNG",
        "outputId": "43e2a596-f0d0-4a0e-d394-301b4e5b1c6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'total': 535,\n",
              "  'empty_prediction': np.int64(0),\n",
              "  'prediction_with_number': np.int64(114),\n",
              "  'reference_with_number': np.int64(297),\n",
              "  'rule_correct': np.int64(47),\n",
              "  'llm_candidates': np.int64(198)},\n",
              " {'empty_prediction': np.float64(0.0),\n",
              "  'prediction_with_number': np.float64(0.213),\n",
              "  'reference_with_number': np.float64(0.555)})"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re, pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"infovqa_clean_rulebaseline.csv\")\n",
        "\n",
        "def has_num_or_pct(s):\n",
        "    return bool(re.search(r\"[-+]?\\d+(?:\\.\\d+)?%?\", str(s)))\n",
        "\n",
        "stats = {\n",
        "    \"total\": len(df),\n",
        "    \"empty_prediction\": (df[\"prediction\"].str.len()==0).sum(),\n",
        "    \"prediction_with_number\": df[\"prediction\"].apply(has_num_or_pct).sum(),\n",
        "    \"reference_with_number\": df[\"reference\"].apply(has_num_or_pct).sum(),\n",
        "    \"rule_correct\": (df[\"rule_score\"]==1).sum(),\n",
        "    \"llm_candidates\": ((df[\"rule_score\"]==0) & (df[\"prediction\"].str.len()>0)).sum(),\n",
        "}\n",
        "stats, {k: round(v/len(df),3) for k,v in stats.items() if k not in [\"total\",\"rule_correct\",\"llm_candidates\"]}\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "068c7727c0ec40e5ab8871e8e3c26faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0731eac36abe4fefa56eb9d072e887a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08a75c4f551f4e4a9cf150c23070a9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b5dbf99ed0d440b9f147f59e31f68c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f6ada349ee24bb0b8c8208364b183c8",
            "placeholder": "​",
            "style": "IPY_MODEL_1dd07dbfe884433596959542cc7afc3a",
            "value": " 443/443 [00:00&lt;00:00, 60.6kB/s]"
          }
        },
        "18cbee89399c4e3db6a92a264bbf161c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dd07dbfe884433596959542cc7afc3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20601b4d02d04ae498532424e80217f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e06ee01dff6e4968a9abb2a3f37b0393",
              "IPY_MODEL_7647c8eaa4ec4c02be1951d49fef33ab",
              "IPY_MODEL_401f886141bd4d4a8651dc4908bbe2cd"
            ],
            "layout": "IPY_MODEL_7a8cc50b39e14ee395125f27511fe60b"
          }
        },
        "2118c51adb6f4f978534760011a1e35b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "238cf2e5927c4bb281c034a2eba6e293": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "272d6e662ee144a9b4e4ac813911f000": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2118c51adb6f4f978534760011a1e35b",
            "placeholder": "​",
            "style": "IPY_MODEL_cd9ffe2f57864c6abb50ec809ac0ded9",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 83.9MB/s]"
          }
        },
        "2ab40afb7c9c4987a4f21efe494cd61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d7889d15aef4996a9d79ee9101c5c00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "304d69dd47e446cca66abf74528c5f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36192f189ebc4f68a9f594c009481477": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdd3282c594841658fb7383e27a80957",
            "placeholder": "​",
            "style": "IPY_MODEL_e96f6b0cbfdb491d95f57e7cdc080bfd",
            "value": "tokenizer.json: 100%"
          }
        },
        "361d2d3c655640ac94b69ff617a28b63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b4c344892849569ac29eef13216bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e08847a1e9974824be13fe6cab5dbe81",
            "max": 17098107,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbe36e500d574abfa8b738a48a1b0d9b",
            "value": 17098107
          }
        },
        "39a94c52445f40348498a6c7e587566d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e4f92e2d6854b0096e8bb1104fa84c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43d4039d72e742ca8394654df2a4f88a",
              "IPY_MODEL_f988e0f3d1fb4f0db7e2c24c87c8c4cf",
              "IPY_MODEL_da0e9fea99a843cea1d152661af20754"
            ],
            "layout": "IPY_MODEL_43d3ed54570940989c30b953d5dcbba8"
          }
        },
        "401f886141bd4d4a8651dc4908bbe2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8c071bee4434ad49ade2ce4815678ba",
            "placeholder": "​",
            "style": "IPY_MODEL_238cf2e5927c4bb281c034a2eba6e293",
            "value": " 2.24G/2.24G [00:04&lt;00:00, 431MB/s]"
          }
        },
        "43d3ed54570940989c30b953d5dcbba8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d4039d72e742ca8394654df2a4f88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0731eac36abe4fefa56eb9d072e887a0",
            "placeholder": "​",
            "style": "IPY_MODEL_2ab40afb7c9c4987a4f21efe494cd61e",
            "value": "config.json: 100%"
          }
        },
        "4420891b52d04fe5b2c23662e0e9a927": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46c13e0346424e678996341ca7491f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_361d2d3c655640ac94b69ff617a28b63",
            "max": 279,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a13b37cfc4c743c8989932f83c0d204e",
            "value": 279
          }
        },
        "4d1c69f74dae402ca79e06b9fb082a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f2f9702348647c0a8d3bc7db1b2ca80",
              "IPY_MODEL_46c13e0346424e678996341ca7491f7a",
              "IPY_MODEL_5046908e401e48deb147026f37efaef5"
            ],
            "layout": "IPY_MODEL_c111c1d6d3164b0b8c49a762f5b1f68f"
          }
        },
        "4eded3bbeddd45ae8159e8c8f64eba73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5936f7f3f0f64fd59e54b4a9aae28753",
            "placeholder": "​",
            "style": "IPY_MODEL_a21b184b118d4fec87b54ca1f0c3c432",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "5046908e401e48deb147026f37efaef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cc559e9b9b94b479b7d5a179818034d",
            "placeholder": "​",
            "style": "IPY_MODEL_4420891b52d04fe5b2c23662e0e9a927",
            "value": " 279/279 [00:00&lt;00:00, 39.8kB/s]"
          }
        },
        "58d24bf56a4541bdb90c56ad12b80399": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5936f7f3f0f64fd59e54b4a9aae28753": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61cb1e94144b475eb42d0bf65653188c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73be6589f4504122865ad374d62c94f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7647c8eaa4ec4c02be1951d49fef33ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6fccedcf8e745a69a433201528b3d39",
            "max": 2239618772,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73be6589f4504122865ad374d62c94f9",
            "value": 2239618772
          }
        },
        "76994a1ec3254211919ace0017ae567a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8cc50b39e14ee395125f27511fe60b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f6ada349ee24bb0b8c8208364b183c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b204a6cac4841719f2493e91a50b9db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cc559e9b9b94b479b7d5a179818034d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a129ff80ce44a28abe62acc4a24085": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "926b0aa07a3b41e2bd5ad58fe42e00e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61cb1e94144b475eb42d0bf65653188c",
            "max": 443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_068c7727c0ec40e5ab8871e8e3c26faf",
            "value": 443
          }
        },
        "9f2f9702348647c0a8d3bc7db1b2ca80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f431445631749eca952fb8ce9a18dc5",
            "placeholder": "​",
            "style": "IPY_MODEL_b95dbd5f636d4dbf87415b1c88350f26",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9f431445631749eca952fb8ce9a18dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a13b37cfc4c743c8989932f83c0d204e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a21b184b118d4fec87b54ca1f0c3c432": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a91fe0f14db74a0f8d6dd6ed6a96c7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36192f189ebc4f68a9f594c009481477",
              "IPY_MODEL_37b4c344892849569ac29eef13216bba",
              "IPY_MODEL_cd9e12817c17405c8784264a67f0c045"
            ],
            "layout": "IPY_MODEL_304d69dd47e446cca66abf74528c5f0a"
          }
        },
        "b24d789382f143e08dfd50a2d81c59dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d7889d15aef4996a9d79ee9101c5c00",
            "placeholder": "​",
            "style": "IPY_MODEL_bd9e830ffc0d4135a0da9ee43631a5ba",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "b824ea81c26a4d2f8024089cd139b472": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b697a08d7148c2a75285cf73b2c3f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b95dbd5f636d4dbf87415b1c88350f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd9e830ffc0d4135a0da9ee43631a5ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c111c1d6d3164b0b8c49a762f5b1f68f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6fccedcf8e745a69a433201528b3d39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c842cb4c289b4e8db51a190bef08d1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b24d789382f143e08dfd50a2d81c59dc",
              "IPY_MODEL_cd027e14421249018037d6d4406b7fe0",
              "IPY_MODEL_272d6e662ee144a9b4e4ac813911f000"
            ],
            "layout": "IPY_MODEL_ec359cc2e0d749e1887e8f55a0eb0f67"
          }
        },
        "cd027e14421249018037d6d4406b7fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18cbee89399c4e3db6a92a264bbf161c",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58d24bf56a4541bdb90c56ad12b80399",
            "value": 5069051
          }
        },
        "cd9e12817c17405c8784264a67f0c045": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39a94c52445f40348498a6c7e587566d",
            "placeholder": "​",
            "style": "IPY_MODEL_08a75c4f551f4e4a9cf150c23070a9b0",
            "value": " 17.1M/17.1M [00:00&lt;00:00, 121MB/s]"
          }
        },
        "cd9ffe2f57864c6abb50ec809ac0ded9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdd3282c594841658fb7383e27a80957": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8c071bee4434ad49ade2ce4815678ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da0e9fea99a843cea1d152661af20754": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b697a08d7148c2a75285cf73b2c3f1",
            "placeholder": "​",
            "style": "IPY_MODEL_91a129ff80ce44a28abe62acc4a24085",
            "value": " 801/801 [00:00&lt;00:00, 113kB/s]"
          }
        },
        "e06ee01dff6e4968a9abb2a3f37b0393": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e720ed9ea3e64d64b3850e3247b6cf42",
            "placeholder": "​",
            "style": "IPY_MODEL_8b204a6cac4841719f2493e91a50b9db",
            "value": "model.safetensors: 100%"
          }
        },
        "e08847a1e9974824be13fe6cab5dbe81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7038e8fd0c448378b5026fc61e94a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eded3bbeddd45ae8159e8c8f64eba73",
              "IPY_MODEL_926b0aa07a3b41e2bd5ad58fe42e00e7",
              "IPY_MODEL_0b5dbf99ed0d440b9f147f59e31f68c5"
            ],
            "layout": "IPY_MODEL_76994a1ec3254211919ace0017ae567a"
          }
        },
        "e720ed9ea3e64d64b3850e3247b6cf42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e96f6b0cbfdb491d95f57e7cdc080bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec359cc2e0d749e1887e8f55a0eb0f67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0c34de623e9465ea1993e99d44d6f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f988e0f3d1fb4f0db7e2c24c87c8c4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b824ea81c26a4d2f8024089cd139b472",
            "max": 801,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0c34de623e9465ea1993e99d44d6f6a",
            "value": 801
          }
        },
        "fbe36e500d574abfa8b738a48a1b0d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
